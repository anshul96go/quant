{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff03b791",
   "metadata": {},
   "source": [
    "# 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ec1f41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats.mstats import winsorize\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Importing libraries\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('fivethirtyeight') \n",
    "# Above is a special style template for matplotlib, highly useful for visualizing time series data\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "from plotly import tools\n",
    "# import plotly.plotly as py\n",
    "# from plotly.offline import init_notebook_mode, iplot\n",
    "# init_notebook_mode(connected=True)\n",
    "# import plotly.graph_objs as go\n",
    "# import plotly.figure_factory as ff\n",
    "import statsmodels.api as sm\n",
    "from numpy.random import normal, seed\n",
    "from scipy.stats import norm\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428379c9",
   "metadata": {},
   "source": [
    "# Trial 1: All Variables + No Feature Engineering + No Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e3fd8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'model': 'ols', 'lag': 0, 'alpha': None, 'test_rmse': 0.017675004543294435}, {'model': 'lasso', 'lag': 0, 'alpha': 0.0, 'test_rmse': 0.01715482059514648}, {'model': 'ridge', 'lag': 0, 'alpha': 0.0, 'test_rmse': 0.017675004553041378}, {'model': 'elastic_net', 'lag': 0, 'alpha': (0.0, 0.0), 'test_rmse': 0.01715482059514648}]\n",
      "[{'model': 'ols', 'lag': 1, 'alpha': None, 'test_rmse': 0.017674983096937807}, {'model': 'lasso', 'lag': 1, 'alpha': 0.0, 'test_rmse': 0.017147756912483554}, {'model': 'ridge', 'lag': 1, 'alpha': 0.0, 'test_rmse': 0.017674983106246236}, {'model': 'elastic_net', 'lag': 1, 'alpha': (0.0, 0.0), 'test_rmse': 0.017147756912483554}]\n",
      "[{'model': 'ols', 'lag': 3, 'alpha': None, 'test_rmse': 0.01765760189505941}, {'model': 'lasso', 'lag': 3, 'alpha': 0.0, 'test_rmse': 0.017119545839501732}, {'model': 'ridge', 'lag': 3, 'alpha': 0.1, 'test_rmse': 0.017063730786888477}, {'model': 'elastic_net', 'lag': 3, 'alpha': (0.0, 0.0), 'test_rmse': 0.017119545839501732}]\n",
      "[{'model': 'ols', 'lag': 5, 'alpha': None, 'test_rmse': 0.017640096995254498}, {'model': 'lasso', 'lag': 5, 'alpha': 0.0, 'test_rmse': 0.01709691693540716}, {'model': 'ridge', 'lag': 5, 'alpha': 0.1, 'test_rmse': 0.017052037120164773}, {'model': 'elastic_net', 'lag': 5, 'alpha': (0.0, 0.0), 'test_rmse': 0.01709691693540716}]\n",
      "[{'model': 'ols', 'lag': 7, 'alpha': None, 'test_rmse': 0.017766216342163896}, {'model': 'lasso', 'lag': 7, 'alpha': 0.0, 'test_rmse': 0.017260134724987074}, {'model': 'ridge', 'lag': 7, 'alpha': 0.1, 'test_rmse': 0.017204463043347933}, {'model': 'elastic_net', 'lag': 7, 'alpha': (0.0, 0.0), 'test_rmse': 0.017260134724987074}]\n",
      "[{'model': 'ols', 'lag': 10, 'alpha': None, 'test_rmse': 0.01785401179201048}, {'model': 'lasso', 'lag': 10, 'alpha': 0.0, 'test_rmse': 0.01733532754708348}, {'model': 'ridge', 'lag': 10, 'alpha': 0.0, 'test_rmse': 0.017854011793807446}, {'model': 'elastic_net', 'lag': 10, 'alpha': (0.0, 0.0), 'test_rmse': 0.01733532754708348}]\n",
      "[{'model': 'ols', 'lag': 14, 'alpha': None, 'test_rmse': 0.017831070704004838}, {'model': 'lasso', 'lag': 14, 'alpha': 0.0, 'test_rmse': 0.017371893475981396}, {'model': 'ridge', 'lag': 14, 'alpha': 0.0, 'test_rmse': 0.01783107070615279}, {'model': 'elastic_net', 'lag': 14, 'alpha': (0.0, 0.0), 'test_rmse': 0.017371893475981396}]\n",
      "[{'model': 'ols', 'lag': 20, 'alpha': None, 'test_rmse': 0.017761215204830066}, {'model': 'lasso', 'lag': 20, 'alpha': 0.0, 'test_rmse': 0.017299023447304045}, {'model': 'ridge', 'lag': 20, 'alpha': 0.0, 'test_rmse': 0.01776121520530538}, {'model': 'elastic_net', 'lag': 20, 'alpha': (0.0, 0.0), 'test_rmse': 0.017299023447304045}]\n",
      "[{'model': 'ols', 'lag': 21, 'alpha': None, 'test_rmse': 0.017772811710481166}, {'model': 'lasso', 'lag': 21, 'alpha': 0.0, 'test_rmse': 0.017316223634693984}, {'model': 'ridge', 'lag': 21, 'alpha': 1.0, 'test_rmse': 0.017224929694975157}, {'model': 'elastic_net', 'lag': 21, 'alpha': (0.0, 0.0), 'test_rmse': 0.017316223634693984}]\n",
      "[{'model': 'ols', 'lag': 22, 'alpha': None, 'test_rmse': 0.017817741125579132}, {'model': 'lasso', 'lag': 22, 'alpha': 0.0, 'test_rmse': 0.01736385686611632}, {'model': 'ridge', 'lag': 22, 'alpha': 1.0, 'test_rmse': 0.01728218725333681}, {'model': 'elastic_net', 'lag': 22, 'alpha': (0.0, 0.0), 'test_rmse': 0.01736385686611632}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.016311463995903823"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model:\n",
    "    \n",
    "    def get_target(self,df):\n",
    "        df['return'] = (df['f24'].shift(-78) - df['f24']) / df['f24']\n",
    "        df['return'] = df['return'].replace([np.inf,-np.inf],0)\n",
    "        return df[['return']]\n",
    "    \n",
    "    \n",
    "    def prepare_features(self, df):\n",
    "        \"\"\"\n",
    "        :param df: this is the data you want to use to prepare the features for your model\n",
    "        :return: X, a matrix of features (can be a numpy array or a pandas dataframe, your choice!)\n",
    "        \"\"\"\n",
    "        # todo: implement this function - you can use some of the features given to you or you can build a batch of\n",
    "        #  your own based on the data that you are given.\n",
    "        # *** PLEASE ENSURE THAT DO NOT INTRODUCE A LOOKAHEAD IN THIS MATRIX ***\n",
    "        # *** Bonus points for coding a function that tests against lookahead in X ***\n",
    "        \n",
    "        ## 1. Data Transformation\n",
    "#         return_type_columns = ['f0','f1','f2','f3','f11','f12']\n",
    "#         price_type_columns = ['f4', 'f5', 'f6', 'f7', 'f8', 'f9',\n",
    "#            'f10', 'f13', 'f16', 'f17', 'f18', 'f19',\n",
    "#            'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29',\n",
    "#            'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39',\n",
    "#            'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49',\n",
    "#            'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59',\n",
    "#            'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69',\n",
    "#            'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76']\n",
    "#         integer_type_columns = ['f14','f15','f77','f78']\n",
    "\n",
    "#         for col in price_type_columns:\n",
    "#             df[col] = (df[col] - df[col].shift(78))/df[col].shift(78)\n",
    "    \n",
    "#         for col in integer_type_columns:\n",
    "#             df[col] = (df[col] - df[col].shift(78))/df[col].shift(78)\n",
    "        \n",
    "        X = df\n",
    "        \n",
    "        # handle case of infinity    \n",
    "        X = X.replace([np.inf],1)\n",
    "        X = X.replace([-np.inf],-1)\n",
    "        \n",
    "        \n",
    "#         ## 2. Drop highly correlated variables\n",
    "#         X.drop(columns=['f5','f6','f7','f9','f8'],inplace=True)\n",
    "#         X.drop(columns=['f25','f26','f28','f29','f31','f32','f34','f35'],inplace=True)\n",
    "#         X.drop(columns=['f37','f38','f39','f42','f44','f45','f47','f48'],inplace=True)\n",
    "#         X.drop(columns=['f51','f52','f54','f55','f57','f58','f60','f61'],inplace=True)\n",
    "#         X.drop(columns=['f65','f64','f67','f63','f71','f70','f74','f73'],inplace=True)\n",
    "        \n",
    "        \n",
    "#         ## 3. Outlier Treatment\n",
    "#         window_size = 20*79  # 1 month (working days only) \n",
    "#         threshold = 2\n",
    "#         rolling_mean = X.rolling(window=window_size, min_periods=1).mean()\n",
    "#         rolling_std = X.rolling(window=window_size, min_periods=1).std()\n",
    "#         lower_bound = rolling_mean - threshold * rolling_std\n",
    "#         upper_bound = rolling_mean + threshold * rolling_std\n",
    "#         req_cols = list(X.columns)\n",
    "#         req_cols.remove('return')\n",
    "#         print(\"req_cols without 'return' \", req_cols)\n",
    "#         for column in req_cols:   \n",
    "#             X[column] = X[column].clip(lower=lower_bound[column], upper=upper_bound[column], axis=0)\n",
    "\n",
    "        # include lag column\n",
    "        column_name = 'return'\n",
    "        for i in range(1, self.lag + 1):\n",
    "            lagged_column_name = f'{column_name}_lag_{i}'\n",
    "            X[lagged_column_name] = X[column_name].shift(i*78)\n",
    "\n",
    "        # delete return columns\n",
    "        del X['return']\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    \n",
    "    def read_data(self,path_to_data):\n",
    "        data = pd.read_csv(path_to_data, index_col='time', parse_dates=['time'])\n",
    "        data.index = pd.to_datetime(data.index, format='%d-%m-%Y %H:%M')\n",
    "        data.sort_index(inplace=True)\n",
    "        data = data.fillna(method='ffill')\n",
    "        return data\n",
    "        \n",
    "    \n",
    "    def fit(self, path_to_train_csv, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        ### AG:  TASKS\n",
    "        ## Model Selection: \n",
    "            Linear: Base Model\n",
    "            Ridge : Handles Multicollinearity\n",
    "            RandomForest (large number of uncorrelated features, fail if the potential y values lie outside)\n",
    "            Time Series\n",
    "        ## Train-Test Split to get the optimal model\n",
    "        ## Train complete model\n",
    "        ## Store the optimal model\n",
    "        \"\"\"\n",
    "        \n",
    "        # get the values from kwargs\n",
    "        self.alphas = kwargs['alphas']\n",
    "        self.lag = kwargs['lag']\n",
    "        self.l1_ratio = kwargs['l1_ratio']\n",
    "        \n",
    "        \n",
    "        # todo: read train csv\n",
    "        # todo: do any operation you would like on it\n",
    "        self.train = self.read_data(path_to_train_csv)\n",
    "        \n",
    "        # todo: prepare features for the model fit\n",
    "        self.y = self.get_target(self.train)\n",
    "        self.X = self.prepare_features(self.train)        \n",
    "        \n",
    "        ## AG: Drop missing values\n",
    "        combined = pd.concat([self.X, self.y], axis=1)\n",
    "        combined_clean = combined.dropna()\n",
    "        self.X_clean = combined_clean.drop(columns='return')\n",
    "        self.y_clean = combined_clean['return']\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Sequential split into train, cv, and test sets\n",
    "        total_length = len(self.X_clean)\n",
    "        train_size = int(total_length * 0.8)  # 60% of data for training\n",
    "#         test_size = int(total_length * 0.2)     # 20% of data for cross-validation\n",
    "\n",
    "        X_train,y_train = self.X_clean[:train_size], self.y_clean[:train_size]\n",
    "        X_test,y_test = self.X_clean[train_size:], self.y_clean[train_size:]\n",
    "\n",
    "        \n",
    "        \n",
    "        # Range of hyperparameters to test for Lasso, Ridge, and Elastic Net\n",
    "        best_alpha = None\n",
    "        lowest_cv_rmse = float('inf')\n",
    "        best_model = None\n",
    "        lowest_rmse = float('inf')\n",
    "        best_model_name = None\n",
    "        \n",
    "        res_list = []\n",
    "        \n",
    "        for model_type in args:\n",
    "            if model_type == 'ols':\n",
    "                model = LinearRegression()\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "#                 print(y_pred)\n",
    "#                 print(y_test)\n",
    "                test_rmse = get_rmse(y_test,y_pred)\n",
    "                res_list.append({'model':model_type,'lag':self.lag,'alpha':None,'test_rmse':test_rmse})\n",
    "                \n",
    "                if test_rmse<lowest_rmse:\n",
    "                    lowest_rmse = test_rmse\n",
    "                    best_model = model\n",
    "                    best_model_name = model_type\n",
    "                    \n",
    "            else:\n",
    "                total_length = len(X_train)\n",
    "                train_size = int(total_length * 0.8)\n",
    "                X_train_fold,y_train_fold = X_train[:train_size], y_train[:train_size]\n",
    "                X_cv_fold,y_cv_fold = X_train[train_size:], y_train[train_size:]\n",
    "\n",
    "                # test for lasso model\n",
    "                if model_type=='lasso':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    for alpha in self.alphas:\n",
    "                        model = Lasso(alpha=alpha)\n",
    "                        model.fit(X_train_fold,y_train_fold)\n",
    "                        y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                        non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                        y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                        cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                         print(\"model: {}, alpha: {}, cv_rmse: {}\".format(model_type,alpha,cv_rmse))\n",
    "                        if cv_rmse<lowest_cv_rmse:\n",
    "                            best_alpha = alpha\n",
    "                            lowest_cv_rmse = cv_rmse\n",
    "                    \n",
    "                    # get the test_rmse for the model\n",
    "                    model = Lasso(alpha=best_alpha)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "                    \n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':best_alpha,'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "\n",
    "            \n",
    "                # test for ridge model\n",
    "                if model_type=='ridge':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    for alpha in self.alphas:\n",
    "                        model = Ridge(alpha=alpha)\n",
    "                        model.fit(X_train_fold,y_train_fold)\n",
    "                        y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                        non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                        y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                        cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                         print(\"model: {}, alpha: {}, cv_rmse: {}\".format(model_type,alpha,cv_rmse))\n",
    "                        if cv_rmse<lowest_cv_rmse:\n",
    "                            best_alpha = alpha\n",
    "                            lowest_cv_rmse = cv_rmse\n",
    "                    \n",
    "                    # get the test_rmse for the model\n",
    "                    model = Ridge(alpha=best_alpha)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "                    \n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':best_alpha,'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "\n",
    "                        \n",
    "                        \n",
    "                # test for ridge model\n",
    "                if model_type=='elastic_net':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    best_l1_ratio = 0\n",
    "                    for alpha in self.alphas:\n",
    "                        for l1_ratio in self.l1_ratio:\n",
    "                            model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "                            model.fit(X_train_fold,y_train_fold)\n",
    "                            y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                            non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                            y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                            cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                             print(\"model: {}, alpha: {}, l1_ratio: {},cv_rmse: {}\".format(model_type,alpha,l1_ratio,cv_rmse))\n",
    "                            if cv_rmse<lowest_cv_rmse:\n",
    "                                best_alpha = alpha\n",
    "                                best_l1_ratio = l1_ratio\n",
    "                                lowest_cv_rmse = cv_rmse\n",
    "\n",
    "                    # get the test_rmse for the model\n",
    "                    model = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "\n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':(best_alpha,best_l1_ratio),'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "        \n",
    "    \n",
    "        self.model = best_model\n",
    "        self.model_name = best_model_name\n",
    "        self.res_list = res_list\n",
    "        return self\n",
    "\n",
    "\n",
    "    \n",
    "    def predict(self, path_to_test_csv, *args, **kwargs):\n",
    "        # todo: read test csv\n",
    "        # todo: do any operation you would like on it\n",
    "        self.test = pd.read_csv(path_to_test_csv, index_col='time', parse_dates=['time'])\n",
    "        self.test.index = pd.to_datetime(self.test.index, format='%d-%m-%Y %H:%M')\n",
    "        self.test.sort_index(inplace=True)\n",
    "        self.test = self.test.fillna(method='ffill')\n",
    "    \n",
    "        # todo: prepare features for the model predict\n",
    "        self.y_test = self.get_target(self.test)\n",
    "        self.X_test = self.prepare_features(self.test)\n",
    "        \n",
    "\n",
    "        # todo: calculate your model prediction (call it ypred) using X and any other information you want to use\n",
    "        ypred = pd.Series(np.nan, index=self.X_test.index)\n",
    "        non_nan_rows = ~self.X_test.isnull().any(axis=1)\n",
    "        ypred[non_nan_rows] = self.model.predict(self.X_test[non_nan_rows])\n",
    "\n",
    "        # this follows the scikit-learn pattern by returning ypred\n",
    "        return ypred\n",
    "\n",
    "def get_rmse(ypred,ytest):\n",
    "    combined = pd.concat([ypred, ytest], axis=1)\n",
    "    combined_clean = combined.dropna()\n",
    "    \n",
    "    rmse_ = rmse(combined_clean[0],combined_clean['return'])\n",
    "    return rmse_\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "train_csv_path = '../data/train.csv'\n",
    "test_csv_path = '../data/test.csv'\n",
    "\n",
    "fit_args = ['ols','lasso','ridge','elastic_net']  # todo: populate this as you see fit\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "for l in [0,1,3,5,7,10,14,20,21,22]:\n",
    "    fit_kwargs = {'alphas':np.linspace(0,1,11),'lag':l,'l1_ratio':np.linspace(0,1,11)} # todo: populate this as you see fit\n",
    "    clf = Model()\n",
    "    clf.fit(train_csv_path, *fit_args, **fit_kwargs)\n",
    "    result_df = pd.concat([result_df,pd.DataFrame(clf.res_list)])\n",
    "    print(clf.res_list)\n",
    "\n",
    "result_df.to_csv('result_all_no_fe_no_out.csv')\n",
    "\n",
    "predict_args = []  # todo: populate this as you see fit\n",
    "predict_kwargs = {}  # todo: populate this as you see fit\n",
    "ypred = clf.predict(test_csv_path, *predict_args, **predict_kwargs)\n",
    "get_rmse(ypred, clf.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "354920b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1e22c8",
   "metadata": {},
   "source": [
    "# Trial 2: All Variables + No Feature Engineering + Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93e71030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 0, 'alpha': None, 'test_rmse': 0.01719139300843021}, {'model': 'lasso', 'lag': 0, 'alpha': 1.0, 'test_rmse': 0.016908003536100683}, {'model': 'ridge', 'lag': 0, 'alpha': 1.0, 'test_rmse': 0.01712235306476225}, {'model': 'elastic_net', 'lag': 0, 'alpha': (0.1, 0.0), 'test_rmse': 0.016918405740703767}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 1, 'alpha': None, 'test_rmse': 0.01719524870920626}, {'model': 'lasso', 'lag': 1, 'alpha': 1.0, 'test_rmse': 0.016908003536100683}, {'model': 'ridge', 'lag': 1, 'alpha': 1.0, 'test_rmse': 0.01711994498710361}, {'model': 'elastic_net', 'lag': 1, 'alpha': (0.1, 0.0), 'test_rmse': 0.016918380475343338}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 3, 'alpha': None, 'test_rmse': 0.01717695267561785}, {'model': 'lasso', 'lag': 3, 'alpha': 1.0, 'test_rmse': 0.016908003536100683}, {'model': 'ridge', 'lag': 3, 'alpha': 1.0, 'test_rmse': 0.017094337563884256}, {'model': 'elastic_net', 'lag': 3, 'alpha': (0.1, 0.0), 'test_rmse': 0.01691822978708241}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 5, 'alpha': None, 'test_rmse': 0.017255037094582926}, {'model': 'lasso', 'lag': 5, 'alpha': 1.0, 'test_rmse': 0.016908003536100683}, {'model': 'ridge', 'lag': 5, 'alpha': 0.0, 'test_rmse': 0.01725503709504953}, {'model': 'elastic_net', 'lag': 5, 'alpha': (0.1, 0.0), 'test_rmse': 0.01691786146129075}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 7, 'alpha': None, 'test_rmse': 0.017341759121816194}, {'model': 'lasso', 'lag': 7, 'alpha': 1.0, 'test_rmse': 0.016908003536100683}, {'model': 'ridge', 'lag': 7, 'alpha': 0.0, 'test_rmse': 0.01734175912212109}, {'model': 'elastic_net', 'lag': 7, 'alpha': (0.1, 0.0), 'test_rmse': 0.016918479487679813}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 10, 'alpha': None, 'test_rmse': 0.017410080976097947}, {'model': 'lasso', 'lag': 10, 'alpha': 1.0, 'test_rmse': 0.016908003536100683}, {'model': 'ridge', 'lag': 10, 'alpha': 0.0, 'test_rmse': 0.017410080975993447}, {'model': 'elastic_net', 'lag': 10, 'alpha': (0.1, 0.0), 'test_rmse': 0.016918404170740028}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 14, 'alpha': None, 'test_rmse': 0.017454171493124667}, {'model': 'lasso', 'lag': 14, 'alpha': 1.0, 'test_rmse': 0.016908003536100683}, {'model': 'ridge', 'lag': 14, 'alpha': 1.0, 'test_rmse': 0.017357615602592982}, {'model': 'elastic_net', 'lag': 14, 'alpha': (0.1, 0.0), 'test_rmse': 0.016918934252433286}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 20, 'alpha': None, 'test_rmse': 0.01738707014779182}, {'model': 'lasso', 'lag': 20, 'alpha': 1.0, 'test_rmse': 0.016908003536100683}, {'model': 'ridge', 'lag': 20, 'alpha': 1.0, 'test_rmse': 0.017288017309786425}, {'model': 'elastic_net', 'lag': 20, 'alpha': (0.1, 0.0), 'test_rmse': 0.01691844899318564}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 21, 'alpha': None, 'test_rmse': 0.017396328638991744}, {'model': 'lasso', 'lag': 21, 'alpha': 1.0, 'test_rmse': 0.016908003536100683}, {'model': 'ridge', 'lag': 21, 'alpha': 1.0, 'test_rmse': 0.01731098549855398}, {'model': 'elastic_net', 'lag': 21, 'alpha': (0.1, 0.0), 'test_rmse': 0.01691851741930783}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'model': 'ols', 'lag': 22, 'alpha': None, 'test_rmse': 0.01745237135746263}, {'model': 'lasso', 'lag': 22, 'alpha': 1.0, 'test_rmse': 0.016908003536100683}, {'model': 'ridge', 'lag': 22, 'alpha': 1.0, 'test_rmse': 0.01737343653108284}, {'model': 'elastic_net', 'lag': 22, 'alpha': (0.1, 0.0), 'test_rmse': 0.016918788137697306}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.015569797700754798"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model:\n",
    "    \n",
    "    def get_target(self,df):\n",
    "        df['return'] = (df['f24'].shift(-78) - df['f24']) / df['f24']\n",
    "        df['return'] = df['return'].replace([np.inf,-np.inf],0)\n",
    "        return df[['return']]\n",
    "    \n",
    "    \n",
    "    def prepare_features(self, df):\n",
    "        \"\"\"\n",
    "        :param df: this is the data you want to use to prepare the features for your model\n",
    "        :return: X, a matrix of features (can be a numpy array or a pandas dataframe, your choice!)\n",
    "        \"\"\"\n",
    "        # todo: implement this function - you can use some of the features given to you or you can build a batch of\n",
    "        #  your own based on the data that you are given.\n",
    "        # *** PLEASE ENSURE THAT DO NOT INTRODUCE A LOOKAHEAD IN THIS MATRIX ***\n",
    "        # *** Bonus points for coding a function that tests against lookahead in X ***\n",
    "        \n",
    "        ## 1. Data Transformation\n",
    "#         return_type_columns = ['f0','f1','f2','f3','f11','f12']\n",
    "#         price_type_columns = ['f4', 'f5', 'f6', 'f7', 'f8', 'f9',\n",
    "#            'f10', 'f13', 'f16', 'f17', 'f18', 'f19',\n",
    "#            'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29',\n",
    "#            'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39',\n",
    "#            'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49',\n",
    "#            'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59',\n",
    "#            'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69',\n",
    "#            'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76']\n",
    "#         integer_type_columns = ['f14','f15','f77','f78']\n",
    "\n",
    "#         for col in price_type_columns:\n",
    "#             df[col] = (df[col] - df[col].shift(78))/df[col].shift(78)\n",
    "    \n",
    "#         for col in integer_type_columns:\n",
    "#             df[col] = (df[col] - df[col].shift(78))/df[col].shift(78)\n",
    "        \n",
    "        X = df\n",
    "        \n",
    "        # handle case of infinity    \n",
    "        X = X.replace([np.inf],1)\n",
    "        X = X.replace([-np.inf],-1)\n",
    "        \n",
    "        \n",
    "#         ## 2. Drop highly correlated variables\n",
    "#         X.drop(columns=['f5','f6','f7','f9','f8'],inplace=True)\n",
    "#         X.drop(columns=['f25','f26','f28','f29','f31','f32','f34','f35'],inplace=True)\n",
    "#         X.drop(columns=['f37','f38','f39','f42','f44','f45','f47','f48'],inplace=True)\n",
    "#         X.drop(columns=['f51','f52','f54','f55','f57','f58','f60','f61'],inplace=True)\n",
    "#         X.drop(columns=['f65','f64','f67','f63','f71','f70','f74','f73'],inplace=True)\n",
    "        \n",
    "        \n",
    "        ## 3. Outlier Treatment\n",
    "        window_size = 20*79  # 1 month (working days only) \n",
    "        threshold = 2\n",
    "        rolling_mean = X.rolling(window=window_size, min_periods=1).mean()\n",
    "        rolling_std = X.rolling(window=window_size, min_periods=1).std()\n",
    "        lower_bound = rolling_mean - threshold * rolling_std\n",
    "        upper_bound = rolling_mean + threshold * rolling_std\n",
    "        req_cols = list(X.columns)\n",
    "        req_cols.remove('return')\n",
    "        print(\"req_cols without 'return' \", req_cols)\n",
    "        for column in req_cols:   \n",
    "            X[column] = X[column].clip(lower=lower_bound[column], upper=upper_bound[column], axis=0)\n",
    "\n",
    "        # include lag column\n",
    "        column_name = 'return'\n",
    "        for i in range(1, self.lag + 1):\n",
    "            lagged_column_name = f'{column_name}_lag_{i}'\n",
    "            X[lagged_column_name] = X[column_name].shift(i*78)\n",
    "\n",
    "        # delete return columns\n",
    "        del X['return']\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    \n",
    "    def read_data(self,path_to_data):\n",
    "        data = pd.read_csv(path_to_data, index_col='time', parse_dates=['time'])\n",
    "        data.index = pd.to_datetime(data.index, format='%d-%m-%Y %H:%M')\n",
    "        data.sort_index(inplace=True)\n",
    "        data = data.fillna(method='ffill')\n",
    "        return data\n",
    "        \n",
    "    \n",
    "    def fit(self, path_to_train_csv, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        ### AG:  TASKS\n",
    "        ## Model Selection: \n",
    "            Linear: Base Model\n",
    "            Ridge : Handles Multicollinearity\n",
    "            RandomForest (large number of uncorrelated features, fail if the potential y values lie outside)\n",
    "            Time Series\n",
    "        ## Train-Test Split to get the optimal model\n",
    "        ## Train complete model\n",
    "        ## Store the optimal model\n",
    "        \"\"\"\n",
    "        \n",
    "        # get the values from kwargs\n",
    "        self.alphas = kwargs['alphas']\n",
    "        self.lag = kwargs['lag']\n",
    "        self.l1_ratio = kwargs['l1_ratio']\n",
    "        \n",
    "        \n",
    "        # todo: read train csv\n",
    "        # todo: do any operation you would like on it\n",
    "        self.train = self.read_data(path_to_train_csv)\n",
    "        \n",
    "        # todo: prepare features for the model fit\n",
    "        self.y = self.get_target(self.train)\n",
    "        self.X = self.prepare_features(self.train)        \n",
    "        \n",
    "        ## AG: Drop missing values\n",
    "        combined = pd.concat([self.X, self.y], axis=1)\n",
    "        combined_clean = combined.dropna()\n",
    "        self.X_clean = combined_clean.drop(columns='return')\n",
    "        self.y_clean = combined_clean['return']\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Sequential split into train, cv, and test sets\n",
    "        total_length = len(self.X_clean)\n",
    "        train_size = int(total_length * 0.8)  # 60% of data for training\n",
    "#         test_size = int(total_length * 0.2)     # 20% of data for cross-validation\n",
    "\n",
    "        X_train,y_train = self.X_clean[:train_size], self.y_clean[:train_size]\n",
    "        X_test,y_test = self.X_clean[train_size:], self.y_clean[train_size:]\n",
    "\n",
    "        \n",
    "        \n",
    "        # Range of hyperparameters to test for Lasso, Ridge, and Elastic Net\n",
    "        best_alpha = None\n",
    "        lowest_cv_rmse = float('inf')\n",
    "        best_model = None\n",
    "        lowest_rmse = float('inf')\n",
    "        best_model_name = None\n",
    "        \n",
    "        res_list = []\n",
    "        \n",
    "        for model_type in args:\n",
    "            if model_type == 'ols':\n",
    "                model = LinearRegression()\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "#                 print(y_pred)\n",
    "#                 print(y_test)\n",
    "                test_rmse = get_rmse(y_test,y_pred)\n",
    "                res_list.append({'model':model_type,'lag':self.lag,'alpha':None,'test_rmse':test_rmse})\n",
    "                \n",
    "                if test_rmse<lowest_rmse:\n",
    "                    lowest_rmse = test_rmse\n",
    "                    best_model = model\n",
    "                    best_model_name = model_type\n",
    "                    \n",
    "            else:\n",
    "                total_length = len(X_train)\n",
    "                train_size = int(total_length * 0.8)\n",
    "                X_train_fold,y_train_fold = X_train[:train_size], y_train[:train_size]\n",
    "                X_cv_fold,y_cv_fold = X_train[train_size:], y_train[train_size:]\n",
    "\n",
    "                # test for lasso model\n",
    "                if model_type=='lasso':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    for alpha in self.alphas:\n",
    "                        model = Lasso(alpha=alpha)\n",
    "                        model.fit(X_train_fold,y_train_fold)\n",
    "                        y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                        non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                        y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                        cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                         print(\"model: {}, alpha: {}, cv_rmse: {}\".format(model_type,alpha,cv_rmse))\n",
    "                        if cv_rmse<lowest_cv_rmse:\n",
    "                            best_alpha = alpha\n",
    "                            lowest_cv_rmse = cv_rmse\n",
    "                    \n",
    "                    # get the test_rmse for the model\n",
    "                    model = Lasso(alpha=best_alpha)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "                    \n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':best_alpha,'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "\n",
    "            \n",
    "                # test for ridge model\n",
    "                if model_type=='ridge':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    for alpha in self.alphas:\n",
    "                        model = Ridge(alpha=alpha)\n",
    "                        model.fit(X_train_fold,y_train_fold)\n",
    "                        y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                        non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                        y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                        cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                         print(\"model: {}, alpha: {}, cv_rmse: {}\".format(model_type,alpha,cv_rmse))\n",
    "                        if cv_rmse<lowest_cv_rmse:\n",
    "                            best_alpha = alpha\n",
    "                            lowest_cv_rmse = cv_rmse\n",
    "                    \n",
    "                    # get the test_rmse for the model\n",
    "                    model = Ridge(alpha=best_alpha)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "                    \n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':best_alpha,'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "\n",
    "                        \n",
    "                        \n",
    "                # test for ridge model\n",
    "                if model_type=='elastic_net':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    best_l1_ratio = 0\n",
    "                    for alpha in self.alphas:\n",
    "                        for l1_ratio in self.l1_ratio:\n",
    "                            model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "                            model.fit(X_train_fold,y_train_fold)\n",
    "                            y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                            non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                            y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                            cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                             print(\"model: {}, alpha: {}, l1_ratio: {},cv_rmse: {}\".format(model_type,alpha,l1_ratio,cv_rmse))\n",
    "                            if cv_rmse<lowest_cv_rmse:\n",
    "                                best_alpha = alpha\n",
    "                                best_l1_ratio = l1_ratio\n",
    "                                lowest_cv_rmse = cv_rmse\n",
    "\n",
    "                    # get the test_rmse for the model\n",
    "                    model = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "\n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':(best_alpha,best_l1_ratio),'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "        \n",
    "    \n",
    "        self.model = best_model\n",
    "        self.model_name = best_model_name\n",
    "        self.res_list = res_list\n",
    "        return self\n",
    "\n",
    "\n",
    "    \n",
    "    def predict(self, path_to_test_csv, *args, **kwargs):\n",
    "        # todo: read test csv\n",
    "        # todo: do any operation you would like on it\n",
    "        self.test = pd.read_csv(path_to_test_csv, index_col='time', parse_dates=['time'])\n",
    "        self.test.index = pd.to_datetime(self.test.index, format='%d-%m-%Y %H:%M')\n",
    "        self.test.sort_index(inplace=True)\n",
    "        self.test = self.test.fillna(method='ffill')\n",
    "    \n",
    "        # todo: prepare features for the model predict\n",
    "        self.y_test = self.get_target(self.test)\n",
    "        self.X_test = self.prepare_features(self.test)\n",
    "        \n",
    "\n",
    "        # todo: calculate your model prediction (call it ypred) using X and any other information you want to use\n",
    "        ypred = pd.Series(np.nan, index=self.X_test.index)\n",
    "        non_nan_rows = ~self.X_test.isnull().any(axis=1)\n",
    "        ypred[non_nan_rows] = self.model.predict(self.X_test[non_nan_rows])\n",
    "\n",
    "        # this follows the scikit-learn pattern by returning ypred\n",
    "        return ypred\n",
    "\n",
    "def get_rmse(ypred,ytest):\n",
    "    combined = pd.concat([ypred, ytest], axis=1)\n",
    "    combined_clean = combined.dropna()\n",
    "    \n",
    "    rmse_ = rmse(combined_clean[0],combined_clean['return'])\n",
    "    return rmse_\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "train_csv_path = '../data/train.csv'\n",
    "test_csv_path = '../data/test.csv'\n",
    "\n",
    "fit_args = ['ols','lasso','ridge','elastic_net']  # todo: populate this as you see fit\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "for l in [0,1,3,5,7,10,14,20,21,22]:\n",
    "    fit_kwargs = {'alphas':np.linspace(0,1,11),'lag':l,'l1_ratio':np.linspace(0,1,11)} # todo: populate this as you see fit\n",
    "    clf = Model()\n",
    "    clf.fit(train_csv_path, *fit_args, **fit_kwargs)\n",
    "    result_df = pd.concat([result_df,pd.DataFrame(clf.res_list)])\n",
    "    print(clf.res_list)\n",
    "\n",
    "result_df.to_csv('result_all_no_fe_out.csv')\n",
    "\n",
    "predict_args = []  # todo: populate this as you see fit\n",
    "predict_kwargs = {}  # todo: populate this as you see fit\n",
    "ypred = clf.predict(test_csv_path, *predict_args, **predict_kwargs)\n",
    "get_rmse(ypred, clf.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "766e6508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ee3253",
   "metadata": {},
   "source": [
    "# Trial 3: All Variables + Feature Engineering + No Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "031aff21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'model': 'ols', 'lag': 0, 'alpha': None, 'test_rmse': 0.01724592048906472}, {'model': 'lasso', 'lag': 0, 'alpha': 0.0, 'test_rmse': 0.017211932622749757}, {'model': 'ridge', 'lag': 0, 'alpha': 1.0, 'test_rmse': 0.017227570414129468}, {'model': 'elastic_net', 'lag': 0, 'alpha': (0.0, 0.0), 'test_rmse': 0.017211932622749757}]\n",
      "[{'model': 'ols', 'lag': 1, 'alpha': None, 'test_rmse': 0.0172459204890652}, {'model': 'lasso', 'lag': 1, 'alpha': 0.0, 'test_rmse': 0.01721152792870006}, {'model': 'ridge', 'lag': 1, 'alpha': 1.0, 'test_rmse': 0.01722720765550979}, {'model': 'elastic_net', 'lag': 1, 'alpha': (0.0, 0.0), 'test_rmse': 0.01721152792870006}]\n",
      "[{'model': 'ols', 'lag': 3, 'alpha': None, 'test_rmse': 0.017230213749413928}, {'model': 'lasso', 'lag': 3, 'alpha': 0.0, 'test_rmse': 0.017194958548581156}, {'model': 'ridge', 'lag': 3, 'alpha': 1.0, 'test_rmse': 0.01720812244141358}, {'model': 'elastic_net', 'lag': 3, 'alpha': (0.0, 0.0), 'test_rmse': 0.017194958548581156}]\n",
      "[{'model': 'ols', 'lag': 5, 'alpha': None, 'test_rmse': 0.017177534520646163}, {'model': 'lasso', 'lag': 5, 'alpha': 0.0, 'test_rmse': 0.017143699929268022}, {'model': 'ridge', 'lag': 5, 'alpha': 1.0, 'test_rmse': 0.01716256039603746}, {'model': 'elastic_net', 'lag': 5, 'alpha': (0.0, 0.0), 'test_rmse': 0.017143699929268022}]\n",
      "[{'model': 'ols', 'lag': 7, 'alpha': None, 'test_rmse': 0.017211203788572934}, {'model': 'lasso', 'lag': 7, 'alpha': 0.0, 'test_rmse': 0.01717734825797484}, {'model': 'ridge', 'lag': 7, 'alpha': 1.0, 'test_rmse': 0.017197526001542462}, {'model': 'elastic_net', 'lag': 7, 'alpha': (0.0, 0.0), 'test_rmse': 0.01717734825797484}]\n",
      "[{'model': 'ols', 'lag': 10, 'alpha': None, 'test_rmse': 0.017252613271895707}, {'model': 'lasso', 'lag': 10, 'alpha': 0.0, 'test_rmse': 0.017219286330125656}, {'model': 'ridge', 'lag': 10, 'alpha': 1.0, 'test_rmse': 0.01723399231830864}, {'model': 'elastic_net', 'lag': 10, 'alpha': (0.0, 0.0), 'test_rmse': 0.017219286330125656}]\n",
      "[{'model': 'ols', 'lag': 14, 'alpha': None, 'test_rmse': 0.01731483987931271}, {'model': 'lasso', 'lag': 14, 'alpha': 0.0, 'test_rmse': 0.01728277823239466}, {'model': 'ridge', 'lag': 14, 'alpha': 1.0, 'test_rmse': 0.01730268439380026}, {'model': 'elastic_net', 'lag': 14, 'alpha': (0.0, 0.0), 'test_rmse': 0.01728277823239466}]\n",
      "[{'model': 'ols', 'lag': 20, 'alpha': None, 'test_rmse': 0.017323153539130647}, {'model': 'lasso', 'lag': 20, 'alpha': 0.0, 'test_rmse': 0.017291518648379335}, {'model': 'ridge', 'lag': 20, 'alpha': 1.0, 'test_rmse': 0.017299297189153386}, {'model': 'elastic_net', 'lag': 20, 'alpha': (0.0, 0.0), 'test_rmse': 0.017291518648379335}]\n",
      "[{'model': 'ols', 'lag': 21, 'alpha': None, 'test_rmse': 0.017381401381879713}, {'model': 'lasso', 'lag': 21, 'alpha': 0.0, 'test_rmse': 0.017351777294621274}, {'model': 'ridge', 'lag': 21, 'alpha': 1.0, 'test_rmse': 0.017355230130350566}, {'model': 'elastic_net', 'lag': 21, 'alpha': (0.0, 0.0), 'test_rmse': 0.017351777294621274}]\n",
      "[{'model': 'ols', 'lag': 22, 'alpha': None, 'test_rmse': 0.017455407868226806}, {'model': 'lasso', 'lag': 22, 'alpha': 0.0, 'test_rmse': 0.017424906330263345}, {'model': 'ridge', 'lag': 22, 'alpha': 1.0, 'test_rmse': 0.017424986063321074}, {'model': 'elastic_net', 'lag': 22, 'alpha': (0.0, 0.0), 'test_rmse': 0.017424906330263345}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01638682388853373"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model:\n",
    "    \n",
    "    def get_target(self,df):\n",
    "        df['return'] = (df['f24'].shift(-78) - df['f24']) / df['f24']\n",
    "        df['return'] = df['return'].replace([np.inf,-np.inf],0)\n",
    "        return df[['return']]\n",
    "    \n",
    "    \n",
    "    def prepare_features(self, df):\n",
    "        \"\"\"\n",
    "        :param df: this is the data you want to use to prepare the features for your model\n",
    "        :return: X, a matrix of features (can be a numpy array or a pandas dataframe, your choice!)\n",
    "        \"\"\"\n",
    "        # todo: implement this function - you can use some of the features given to you or you can build a batch of\n",
    "        #  your own based on the data that you are given.\n",
    "        # *** PLEASE ENSURE THAT DO NOT INTRODUCE A LOOKAHEAD IN THIS MATRIX ***\n",
    "        # *** Bonus points for coding a function that tests against lookahead in X ***\n",
    "        \n",
    "        ## 1. Data Transformation\n",
    "        return_type_columns = ['f0','f1','f2','f3','f11','f12']\n",
    "        price_type_columns = ['f4', 'f5', 'f6', 'f7', 'f8', 'f9',\n",
    "           'f10', 'f13', 'f16', 'f17', 'f18', 'f19',\n",
    "           'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29',\n",
    "           'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39',\n",
    "           'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49',\n",
    "           'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59',\n",
    "           'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69',\n",
    "           'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76']\n",
    "        integer_type_columns = ['f14','f15','f77','f78']\n",
    "\n",
    "        for col in price_type_columns:\n",
    "            df[col] = (df[col] - df[col].shift(78))/df[col].shift(78)\n",
    "    \n",
    "        for col in integer_type_columns:\n",
    "            df[col] = (df[col] - df[col].shift(78))/df[col].shift(78)\n",
    "        \n",
    "        X = df\n",
    "        \n",
    "        # handle case of infinity    \n",
    "        X = X.replace([np.inf],1)\n",
    "        X = X.replace([-np.inf],-1)\n",
    "        \n",
    "        \n",
    "#         ## 2. Drop highly correlated variables\n",
    "#         X.drop(columns=['f5','f6','f7','f9','f8'],inplace=True)\n",
    "#         X.drop(columns=['f25','f26','f28','f29','f31','f32','f34','f35'],inplace=True)\n",
    "#         X.drop(columns=['f37','f38','f39','f42','f44','f45','f47','f48'],inplace=True)\n",
    "#         X.drop(columns=['f51','f52','f54','f55','f57','f58','f60','f61'],inplace=True)\n",
    "#         X.drop(columns=['f65','f64','f67','f63','f71','f70','f74','f73'],inplace=True)\n",
    "        \n",
    "        \n",
    "#         ## 3. Outlier Treatment\n",
    "#         window_size = 20*79  # 1 month (working days only) \n",
    "#         threshold = 2\n",
    "#         rolling_mean = X.rolling(window=window_size, min_periods=1).mean()\n",
    "#         rolling_std = X.rolling(window=window_size, min_periods=1).std()\n",
    "#         lower_bound = rolling_mean - threshold * rolling_std\n",
    "#         upper_bound = rolling_mean + threshold * rolling_std\n",
    "#         req_cols = list(X.columns)\n",
    "#         req_cols.remove('return')\n",
    "#         print(\"req_cols without 'return' \", req_cols)\n",
    "#         for column in req_cols:   \n",
    "#             X[column] = X[column].clip(lower=lower_bound[column], upper=upper_bound[column], axis=0)\n",
    "\n",
    "        # include lag column\n",
    "        column_name = 'return'\n",
    "        for i in range(1, self.lag + 1):\n",
    "            lagged_column_name = f'{column_name}_lag_{i}'\n",
    "            X[lagged_column_name] = X[column_name].shift(i*78)\n",
    "\n",
    "        # delete return columns\n",
    "        del X['return']\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    \n",
    "    def read_data(self,path_to_data):\n",
    "        data = pd.read_csv(path_to_data, index_col='time', parse_dates=['time'])\n",
    "        data.index = pd.to_datetime(data.index, format='%d-%m-%Y %H:%M')\n",
    "        data.sort_index(inplace=True)\n",
    "        data = data.fillna(method='ffill')\n",
    "        return data\n",
    "        \n",
    "    \n",
    "    def fit(self, path_to_train_csv, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        ### AG:  TASKS\n",
    "        ## Model Selection: \n",
    "            Linear: Base Model\n",
    "            Ridge : Handles Multicollinearity\n",
    "            RandomForest (large number of uncorrelated features, fail if the potential y values lie outside)\n",
    "            Time Series\n",
    "        ## Train-Test Split to get the optimal model\n",
    "        ## Train complete model\n",
    "        ## Store the optimal model\n",
    "        \"\"\"\n",
    "        \n",
    "        # get the values from kwargs\n",
    "        self.alphas = kwargs['alphas']\n",
    "        self.lag = kwargs['lag']\n",
    "        self.l1_ratio = kwargs['l1_ratio']\n",
    "        \n",
    "        \n",
    "        # todo: read train csv\n",
    "        # todo: do any operation you would like on it\n",
    "        self.train = self.read_data(path_to_train_csv)\n",
    "        \n",
    "        # todo: prepare features for the model fit\n",
    "        self.y = self.get_target(self.train)\n",
    "        self.X = self.prepare_features(self.train)        \n",
    "        \n",
    "        ## AG: Drop missing values\n",
    "        combined = pd.concat([self.X, self.y], axis=1)\n",
    "        combined_clean = combined.dropna()\n",
    "        self.X_clean = combined_clean.drop(columns='return')\n",
    "        self.y_clean = combined_clean['return']\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Sequential split into train, cv, and test sets\n",
    "        total_length = len(self.X_clean)\n",
    "        train_size = int(total_length * 0.8)  # 60% of data for training\n",
    "#         test_size = int(total_length * 0.2)     # 20% of data for cross-validation\n",
    "\n",
    "        X_train,y_train = self.X_clean[:train_size], self.y_clean[:train_size]\n",
    "        X_test,y_test = self.X_clean[train_size:], self.y_clean[train_size:]\n",
    "\n",
    "        \n",
    "        \n",
    "        # Range of hyperparameters to test for Lasso, Ridge, and Elastic Net\n",
    "        best_alpha = None\n",
    "        lowest_cv_rmse = float('inf')\n",
    "        best_model = None\n",
    "        lowest_rmse = float('inf')\n",
    "        best_model_name = None\n",
    "        \n",
    "        res_list = []\n",
    "        \n",
    "        for model_type in args:\n",
    "            if model_type == 'ols':\n",
    "                model = LinearRegression()\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "#                 print(y_pred)\n",
    "#                 print(y_test)\n",
    "                test_rmse = get_rmse(y_test,y_pred)\n",
    "                res_list.append({'model':model_type,'lag':self.lag,'alpha':None,'test_rmse':test_rmse})\n",
    "                \n",
    "                if test_rmse<lowest_rmse:\n",
    "                    lowest_rmse = test_rmse\n",
    "                    best_model = model\n",
    "                    best_model_name = model_type\n",
    "                    \n",
    "            else:\n",
    "                total_length = len(X_train)\n",
    "                train_size = int(total_length * 0.8)\n",
    "                X_train_fold,y_train_fold = X_train[:train_size], y_train[:train_size]\n",
    "                X_cv_fold,y_cv_fold = X_train[train_size:], y_train[train_size:]\n",
    "\n",
    "                # test for lasso model\n",
    "                if model_type=='lasso':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    for alpha in self.alphas:\n",
    "                        model = Lasso(alpha=alpha)\n",
    "                        model.fit(X_train_fold,y_train_fold)\n",
    "                        y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                        non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                        y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                        cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                         print(\"model: {}, alpha: {}, cv_rmse: {}\".format(model_type,alpha,cv_rmse))\n",
    "                        if cv_rmse<lowest_cv_rmse:\n",
    "                            best_alpha = alpha\n",
    "                            lowest_cv_rmse = cv_rmse\n",
    "                    \n",
    "                    # get the test_rmse for the model\n",
    "                    model = Lasso(alpha=best_alpha)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "                    \n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':best_alpha,'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "\n",
    "            \n",
    "                # test for ridge model\n",
    "                if model_type=='ridge':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    for alpha in self.alphas:\n",
    "                        model = Ridge(alpha=alpha)\n",
    "                        model.fit(X_train_fold,y_train_fold)\n",
    "                        y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                        non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                        y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                        cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                         print(\"model: {}, alpha: {}, cv_rmse: {}\".format(model_type,alpha,cv_rmse))\n",
    "                        if cv_rmse<lowest_cv_rmse:\n",
    "                            best_alpha = alpha\n",
    "                            lowest_cv_rmse = cv_rmse\n",
    "                    \n",
    "                    # get the test_rmse for the model\n",
    "                    model = Ridge(alpha=best_alpha)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "                    \n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':best_alpha,'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "\n",
    "                        \n",
    "                        \n",
    "                # test for ridge model\n",
    "                if model_type=='elastic_net':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    best_l1_ratio = 0\n",
    "                    for alpha in self.alphas:\n",
    "                        for l1_ratio in self.l1_ratio:\n",
    "                            model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "                            model.fit(X_train_fold,y_train_fold)\n",
    "                            y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                            non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                            y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                            cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                             print(\"model: {}, alpha: {}, l1_ratio: {},cv_rmse: {}\".format(model_type,alpha,l1_ratio,cv_rmse))\n",
    "                            if cv_rmse<lowest_cv_rmse:\n",
    "                                best_alpha = alpha\n",
    "                                best_l1_ratio = l1_ratio\n",
    "                                lowest_cv_rmse = cv_rmse\n",
    "\n",
    "                    # get the test_rmse for the model\n",
    "                    model = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "\n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':(best_alpha,best_l1_ratio),'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "        \n",
    "    \n",
    "        self.model = best_model\n",
    "        self.model_name = best_model_name\n",
    "        self.res_list = res_list\n",
    "        return self\n",
    "\n",
    "\n",
    "    \n",
    "    def predict(self, path_to_test_csv, *args, **kwargs):\n",
    "        # todo: read test csv\n",
    "        # todo: do any operation you would like on it\n",
    "        self.test = pd.read_csv(path_to_test_csv, index_col='time', parse_dates=['time'])\n",
    "        self.test.index = pd.to_datetime(self.test.index, format='%d-%m-%Y %H:%M')\n",
    "        self.test.sort_index(inplace=True)\n",
    "        self.test = self.test.fillna(method='ffill')\n",
    "    \n",
    "        # todo: prepare features for the model predict\n",
    "        self.y_test = self.get_target(self.test)\n",
    "        self.X_test = self.prepare_features(self.test)\n",
    "        \n",
    "\n",
    "        # todo: calculate your model prediction (call it ypred) using X and any other information you want to use\n",
    "        ypred = pd.Series(np.nan, index=self.X_test.index)\n",
    "        non_nan_rows = ~self.X_test.isnull().any(axis=1)\n",
    "        ypred[non_nan_rows] = self.model.predict(self.X_test[non_nan_rows])\n",
    "\n",
    "        # this follows the scikit-learn pattern by returning ypred\n",
    "        return ypred\n",
    "\n",
    "def get_rmse(ypred,ytest):\n",
    "    combined = pd.concat([ypred, ytest], axis=1)\n",
    "    combined_clean = combined.dropna()\n",
    "    \n",
    "    rmse_ = rmse(combined_clean[0],combined_clean['return'])\n",
    "    return rmse_\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "train_csv_path = '../data/train.csv'\n",
    "test_csv_path = '../data/test.csv'\n",
    "\n",
    "fit_args = ['ols','lasso','ridge','elastic_net']  # todo: populate this as you see fit\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "for l in [0,1,3,5,7,10,14,20,21,22]:\n",
    "    fit_kwargs = {'alphas':np.linspace(0,1,11),'lag':l,'l1_ratio':np.linspace(0,1,11)} # todo: populate this as you see fit\n",
    "    clf = Model()\n",
    "    clf.fit(train_csv_path, *fit_args, **fit_kwargs)\n",
    "    result_df = pd.concat([result_df,pd.DataFrame(clf.res_list)])\n",
    "    print(clf.res_list)\n",
    "\n",
    "result_df.to_csv('result_all_fe_no_out.csv')\n",
    "\n",
    "predict_args = []  # todo: populate this as you see fit\n",
    "predict_kwargs = {}  # todo: populate this as you see fit\n",
    "ypred = clf.predict(test_csv_path, *predict_args, **predict_kwargs)\n",
    "get_rmse(ypred, clf.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf6a6310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=0.0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=0.0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso(alpha=0.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023937e0",
   "metadata": {},
   "source": [
    "# Trial 3.1 All + Feat + Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3ab5c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 0, 'alpha': None, 'test_rmse': 0.017010885744742767}, {'model': 'lasso', 'lag': 0, 'alpha': 0.0, 'test_rmse': 0.017001509422965157}, {'model': 'ridge', 'lag': 0, 'alpha': 1.0, 'test_rmse': 0.016949776846943175}, {'model': 'elastic_net', 'lag': 0, 'alpha': (0.0, 0.0), 'test_rmse': 0.017001509422965157}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 1, 'alpha': None, 'test_rmse': 0.01712755534067866}, {'model': 'lasso', 'lag': 1, 'alpha': 0.0, 'test_rmse': 0.01711647841932155}, {'model': 'ridge', 'lag': 1, 'alpha': 1.0, 'test_rmse': 0.016971049981177357}, {'model': 'elastic_net', 'lag': 1, 'alpha': (0.0, 0.0), 'test_rmse': 0.01711647841932155}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 3, 'alpha': None, 'test_rmse': 0.017109964801385154}, {'model': 'lasso', 'lag': 3, 'alpha': 0.0, 'test_rmse': 0.017098884901520107}, {'model': 'ridge', 'lag': 3, 'alpha': 1.0, 'test_rmse': 0.01695558308294839}, {'model': 'elastic_net', 'lag': 3, 'alpha': (0.0, 0.0), 'test_rmse': 0.017098884901520107}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 5, 'alpha': None, 'test_rmse': 0.01704847727799659}, {'model': 'lasso', 'lag': 5, 'alpha': 0.0, 'test_rmse': 0.017036809315070033}, {'model': 'ridge', 'lag': 5, 'alpha': 1.0, 'test_rmse': 0.01689852815664339}, {'model': 'elastic_net', 'lag': 5, 'alpha': (0.0, 0.0), 'test_rmse': 0.017036809315070033}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 7, 'alpha': None, 'test_rmse': 0.01714870422136756}, {'model': 'lasso', 'lag': 7, 'alpha': 0.0, 'test_rmse': 0.017136373420508628}, {'model': 'ridge', 'lag': 7, 'alpha': 1.0, 'test_rmse': 0.0169781788689565}, {'model': 'elastic_net', 'lag': 7, 'alpha': (0.0, 0.0), 'test_rmse': 0.017136373420508628}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 10, 'alpha': None, 'test_rmse': 0.01716979556408271}, {'model': 'lasso', 'lag': 10, 'alpha': 0.0, 'test_rmse': 0.017157832576718456}, {'model': 'ridge', 'lag': 10, 'alpha': 1.0, 'test_rmse': 0.01700249643526048}, {'model': 'elastic_net', 'lag': 10, 'alpha': (0.0, 0.0), 'test_rmse': 0.017157832576718456}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 14, 'alpha': None, 'test_rmse': 0.017257568963214665}, {'model': 'lasso', 'lag': 14, 'alpha': 0.0, 'test_rmse': 0.017245700701657266}, {'model': 'ridge', 'lag': 14, 'alpha': 1.0, 'test_rmse': 0.01708611445595474}, {'model': 'elastic_net', 'lag': 14, 'alpha': (0.0, 0.0), 'test_rmse': 0.017245700701657266}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 20, 'alpha': None, 'test_rmse': 0.01726355266021929}, {'model': 'lasso', 'lag': 20, 'alpha': 0.0, 'test_rmse': 0.01725092532314729}, {'model': 'ridge', 'lag': 20, 'alpha': 1.0, 'test_rmse': 0.01709086593099018}, {'model': 'elastic_net', 'lag': 20, 'alpha': (0.0, 0.0), 'test_rmse': 0.01725092532314729}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 21, 'alpha': None, 'test_rmse': 0.017329558561606728}, {'model': 'lasso', 'lag': 21, 'alpha': 0.0, 'test_rmse': 0.01731700498062545}, {'model': 'ridge', 'lag': 21, 'alpha': 1.0, 'test_rmse': 0.017148930674163818}, {'model': 'elastic_net', 'lag': 21, 'alpha': (0.0, 0.0), 'test_rmse': 0.01731700498062545}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'model': 'ols', 'lag': 22, 'alpha': None, 'test_rmse': 0.017392887002058006}, {'model': 'lasso', 'lag': 22, 'alpha': 0.0, 'test_rmse': 0.017380571260237548}, {'model': 'ridge', 'lag': 22, 'alpha': 1.0, 'test_rmse': 0.017207715714613426}, {'model': 'elastic_net', 'lag': 22, 'alpha': (0.0, 0.0), 'test_rmse': 0.017380571260237548}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.016196190428882228"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model:\n",
    "    \n",
    "    def get_target(self,df):\n",
    "        df['return'] = (df['f24'].shift(-78) - df['f24']) / df['f24']\n",
    "        df['return'] = df['return'].replace([np.inf,-np.inf],0)\n",
    "        return df[['return']]\n",
    "    \n",
    "    \n",
    "    def prepare_features(self, df):\n",
    "        \"\"\"\n",
    "        :param df: this is the data you want to use to prepare the features for your model\n",
    "        :return: X, a matrix of features (can be a numpy array or a pandas dataframe, your choice!)\n",
    "        \"\"\"\n",
    "        # todo: implement this function - you can use some of the features given to you or you can build a batch of\n",
    "        #  your own based on the data that you are given.\n",
    "        # *** PLEASE ENSURE THAT DO NOT INTRODUCE A LOOKAHEAD IN THIS MATRIX ***\n",
    "        # *** Bonus points for coding a function that tests against lookahead in X ***\n",
    "        \n",
    "        ## 1. Data Transformation\n",
    "        return_type_columns = ['f0','f1','f2','f3','f11','f12']\n",
    "        price_type_columns = ['f4', 'f5', 'f6', 'f7', 'f8', 'f9',\n",
    "           'f10', 'f13', 'f16', 'f17', 'f18', 'f19',\n",
    "           'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29',\n",
    "           'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39',\n",
    "           'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49',\n",
    "           'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59',\n",
    "           'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69',\n",
    "           'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76']\n",
    "        integer_type_columns = ['f14','f15','f77','f78']\n",
    "\n",
    "        for col in price_type_columns:\n",
    "            df[col] = (df[col] - df[col].shift(78))/df[col].shift(78)\n",
    "    \n",
    "        for col in integer_type_columns:\n",
    "            df[col] = (df[col] - df[col].shift(78))/df[col].shift(78)\n",
    "        \n",
    "        X = df\n",
    "        \n",
    "        # handle case of infinity    \n",
    "        X = X.replace([np.inf],1)\n",
    "        X = X.replace([-np.inf],-1)\n",
    "        \n",
    "        \n",
    "#         ## 2. Drop highly correlated variables\n",
    "#         X.drop(columns=['f5','f6','f7','f9','f8'],inplace=True)\n",
    "#         X.drop(columns=['f25','f26','f28','f29','f31','f32','f34','f35'],inplace=True)\n",
    "#         X.drop(columns=['f37','f38','f39','f42','f44','f45','f47','f48'],inplace=True)\n",
    "#         X.drop(columns=['f51','f52','f54','f55','f57','f58','f60','f61'],inplace=True)\n",
    "#         X.drop(columns=['f65','f64','f67','f63','f71','f70','f74','f73'],inplace=True)\n",
    "        \n",
    "        \n",
    "        ## 3. Outlier Treatment\n",
    "        window_size = 20*79  # 1 month (working days only) \n",
    "        threshold = 2\n",
    "        rolling_mean = X.rolling(window=window_size, min_periods=1).mean()\n",
    "        rolling_std = X.rolling(window=window_size, min_periods=1).std()\n",
    "        lower_bound = rolling_mean - threshold * rolling_std\n",
    "        upper_bound = rolling_mean + threshold * rolling_std\n",
    "        req_cols = list(X.columns)\n",
    "        req_cols.remove('return')\n",
    "        print(\"req_cols without 'return' \", req_cols)\n",
    "        for column in req_cols:   \n",
    "            X[column] = X[column].clip(lower=lower_bound[column], upper=upper_bound[column], axis=0)\n",
    "\n",
    "        # include lag column\n",
    "        column_name = 'return'\n",
    "        for i in range(1, self.lag + 1):\n",
    "            lagged_column_name = f'{column_name}_lag_{i}'\n",
    "            X[lagged_column_name] = X[column_name].shift(i*78)\n",
    "\n",
    "        # delete return columns\n",
    "        del X['return']\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    \n",
    "    def read_data(self,path_to_data):\n",
    "        data = pd.read_csv(path_to_data, index_col='time', parse_dates=['time'])\n",
    "        data.index = pd.to_datetime(data.index, format='%d-%m-%Y %H:%M')\n",
    "        data.sort_index(inplace=True)\n",
    "        data = data.fillna(method='ffill')\n",
    "        return data\n",
    "        \n",
    "    \n",
    "    def fit(self, path_to_train_csv, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        ### AG:  TASKS\n",
    "        ## Model Selection: \n",
    "            Linear: Base Model\n",
    "            Ridge : Handles Multicollinearity\n",
    "            RandomForest (large number of uncorrelated features, fail if the potential y values lie outside)\n",
    "            Time Series\n",
    "        ## Train-Test Split to get the optimal model\n",
    "        ## Train complete model\n",
    "        ## Store the optimal model\n",
    "        \"\"\"\n",
    "        \n",
    "        # get the values from kwargs\n",
    "        self.alphas = kwargs['alphas']\n",
    "        self.lag = kwargs['lag']\n",
    "        self.l1_ratio = kwargs['l1_ratio']\n",
    "        \n",
    "        \n",
    "        # todo: read train csv\n",
    "        # todo: do any operation you would like on it\n",
    "        self.train = self.read_data(path_to_train_csv)\n",
    "        \n",
    "        # todo: prepare features for the model fit\n",
    "        self.y = self.get_target(self.train)\n",
    "        self.X = self.prepare_features(self.train)        \n",
    "        \n",
    "        ## AG: Drop missing values\n",
    "        combined = pd.concat([self.X, self.y], axis=1)\n",
    "        combined_clean = combined.dropna()\n",
    "        self.X_clean = combined_clean.drop(columns='return')\n",
    "        self.y_clean = combined_clean['return']\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Sequential split into train, cv, and test sets\n",
    "        total_length = len(self.X_clean)\n",
    "        train_size = int(total_length * 0.8)  # 60% of data for training\n",
    "#         test_size = int(total_length * 0.2)     # 20% of data for cross-validation\n",
    "\n",
    "        X_train,y_train = self.X_clean[:train_size], self.y_clean[:train_size]\n",
    "        X_test,y_test = self.X_clean[train_size:], self.y_clean[train_size:]\n",
    "\n",
    "        \n",
    "        \n",
    "        # Range of hyperparameters to test for Lasso, Ridge, and Elastic Net\n",
    "        best_alpha = None\n",
    "        lowest_cv_rmse = float('inf')\n",
    "        best_model = None\n",
    "        lowest_rmse = float('inf')\n",
    "        best_model_name = None\n",
    "        \n",
    "        res_list = []\n",
    "        \n",
    "        for model_type in args:\n",
    "            if model_type == 'ols':\n",
    "                model = LinearRegression()\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "#                 print(y_pred)\n",
    "#                 print(y_test)\n",
    "                test_rmse = get_rmse(y_test,y_pred)\n",
    "                res_list.append({'model':model_type,'lag':self.lag,'alpha':None,'test_rmse':test_rmse})\n",
    "                \n",
    "                if test_rmse<lowest_rmse:\n",
    "                    lowest_rmse = test_rmse\n",
    "                    best_model = model\n",
    "                    best_model_name = model_type\n",
    "                    \n",
    "            else:\n",
    "                total_length = len(X_train)\n",
    "                train_size = int(total_length * 0.8)\n",
    "                X_train_fold,y_train_fold = X_train[:train_size], y_train[:train_size]\n",
    "                X_cv_fold,y_cv_fold = X_train[train_size:], y_train[train_size:]\n",
    "\n",
    "                # test for lasso model\n",
    "                if model_type=='lasso':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    for alpha in self.alphas:\n",
    "                        model = Lasso(alpha=alpha)\n",
    "                        model.fit(X_train_fold,y_train_fold)\n",
    "                        y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                        non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                        y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                        cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                         print(\"model: {}, alpha: {}, cv_rmse: {}\".format(model_type,alpha,cv_rmse))\n",
    "                        if cv_rmse<lowest_cv_rmse:\n",
    "                            best_alpha = alpha\n",
    "                            lowest_cv_rmse = cv_rmse\n",
    "                    \n",
    "                    # get the test_rmse for the model\n",
    "                    model = Lasso(alpha=best_alpha)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "                    \n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':best_alpha,'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "\n",
    "            \n",
    "                # test for ridge model\n",
    "                if model_type=='ridge':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    for alpha in self.alphas:\n",
    "                        model = Ridge(alpha=alpha)\n",
    "                        model.fit(X_train_fold,y_train_fold)\n",
    "                        y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                        non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                        y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                        cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                         print(\"model: {}, alpha: {}, cv_rmse: {}\".format(model_type,alpha,cv_rmse))\n",
    "                        if cv_rmse<lowest_cv_rmse:\n",
    "                            best_alpha = alpha\n",
    "                            lowest_cv_rmse = cv_rmse\n",
    "                    \n",
    "                    # get the test_rmse for the model\n",
    "                    model = Ridge(alpha=best_alpha)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "                    \n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':best_alpha,'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "\n",
    "                        \n",
    "                        \n",
    "                # test for ridge model\n",
    "                if model_type=='elastic_net':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    best_l1_ratio = 0\n",
    "                    for alpha in self.alphas:\n",
    "                        for l1_ratio in self.l1_ratio:\n",
    "                            model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "                            model.fit(X_train_fold,y_train_fold)\n",
    "                            y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                            non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                            y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                            cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                             print(\"model: {}, alpha: {}, l1_ratio: {},cv_rmse: {}\".format(model_type,alpha,l1_ratio,cv_rmse))\n",
    "                            if cv_rmse<lowest_cv_rmse:\n",
    "                                best_alpha = alpha\n",
    "                                best_l1_ratio = l1_ratio\n",
    "                                lowest_cv_rmse = cv_rmse\n",
    "\n",
    "                    # get the test_rmse for the model\n",
    "                    model = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "\n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':(best_alpha,best_l1_ratio),'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "        \n",
    "    \n",
    "        self.model = best_model\n",
    "        self.model_name = best_model_name\n",
    "        self.res_list = res_list\n",
    "        return self\n",
    "\n",
    "\n",
    "    \n",
    "    def predict(self, path_to_test_csv, *args, **kwargs):\n",
    "        # todo: read test csv\n",
    "        # todo: do any operation you would like on it\n",
    "        self.test = pd.read_csv(path_to_test_csv, index_col='time', parse_dates=['time'])\n",
    "        self.test.index = pd.to_datetime(self.test.index, format='%d-%m-%Y %H:%M')\n",
    "        self.test.sort_index(inplace=True)\n",
    "        self.test = self.test.fillna(method='ffill')\n",
    "    \n",
    "        # todo: prepare features for the model predict\n",
    "        self.y_test = self.get_target(self.test)\n",
    "        self.X_test = self.prepare_features(self.test)\n",
    "        \n",
    "\n",
    "        # todo: calculate your model prediction (call it ypred) using X and any other information you want to use\n",
    "        ypred = pd.Series(np.nan, index=self.X_test.index)\n",
    "        non_nan_rows = ~self.X_test.isnull().any(axis=1)\n",
    "        ypred[non_nan_rows] = self.model.predict(self.X_test[non_nan_rows])\n",
    "\n",
    "        # this follows the scikit-learn pattern by returning ypred\n",
    "        return ypred\n",
    "\n",
    "def get_rmse(ypred,ytest):\n",
    "    combined = pd.concat([ypred, ytest], axis=1)\n",
    "    combined_clean = combined.dropna()\n",
    "    \n",
    "    rmse_ = rmse(combined_clean[0],combined_clean['return'])\n",
    "    return rmse_\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "train_csv_path = '../data/train.csv'\n",
    "test_csv_path = '../data/test.csv'\n",
    "\n",
    "fit_args = ['ols','lasso','ridge','elastic_net']  # todo: populate this as you see fit\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "for l in [0,1,3,5,7,10,14,20,21,22]:\n",
    "    fit_kwargs = {'alphas':np.linspace(0,1,11),'lag':l,'l1_ratio':np.linspace(0,1,11)} # todo: populate this as you see fit\n",
    "    clf = Model()\n",
    "    clf.fit(train_csv_path, *fit_args, **fit_kwargs)\n",
    "    result_df = pd.concat([result_df,pd.DataFrame(clf.res_list)])\n",
    "    print(clf.res_list)\n",
    "\n",
    "result_df.to_csv('result_all_fe_out.csv')\n",
    "\n",
    "predict_args = []  # todo: populate this as you see fit\n",
    "predict_kwargs = {}  # todo: populate this as you see fit\n",
    "ypred = clf.predict(test_csv_path, *predict_args, **predict_kwargs)\n",
    "get_rmse(ypred, clf.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e431c8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0762baf",
   "metadata": {},
   "source": [
    "# Trial 4: Selected Variables + No Feature Engineering + No Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbee8e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'model': 'ols', 'lag': 0, 'alpha': None, 'test_rmse': 0.02229447586912438}, {'model': 'lasso', 'lag': 0, 'alpha': 0.0, 'test_rmse': 0.02229447585757825}, {'model': 'ridge', 'lag': 0, 'alpha': 1.0, 'test_rmse': 0.02151265632540858}, {'model': 'elastic_net', 'lag': 0, 'alpha': (0.0, 0.0), 'test_rmse': 0.02229447585757825}]\n",
      "[{'model': 'ols', 'lag': 1, 'alpha': None, 'test_rmse': 0.022529292580297084}, {'model': 'lasso', 'lag': 1, 'alpha': 0.0, 'test_rmse': 0.022529292564137084}, {'model': 'ridge', 'lag': 1, 'alpha': 1.0, 'test_rmse': 0.021646910855221416}, {'model': 'elastic_net', 'lag': 1, 'alpha': (0.0, 0.0), 'test_rmse': 0.022529292564137084}]\n",
      "[{'model': 'ols', 'lag': 3, 'alpha': None, 'test_rmse': 0.022819412000791253}, {'model': 'lasso', 'lag': 3, 'alpha': 1.0, 'test_rmse': 0.017804528407824996}, {'model': 'ridge', 'lag': 3, 'alpha': 1.0, 'test_rmse': 0.021793696375104848}, {'model': 'elastic_net', 'lag': 3, 'alpha': (0.1, 0.0), 'test_rmse': 0.01776256515015456}]\n",
      "[{'model': 'ols', 'lag': 5, 'alpha': None, 'test_rmse': 0.022583443936643566}, {'model': 'lasso', 'lag': 5, 'alpha': 1.0, 'test_rmse': 0.017797314068966712}, {'model': 'ridge', 'lag': 5, 'alpha': 1.0, 'test_rmse': 0.02150943909922995}, {'model': 'elastic_net', 'lag': 5, 'alpha': (0.1, 0.0), 'test_rmse': 0.017756133787483575}]\n",
      "[{'model': 'ols', 'lag': 7, 'alpha': None, 'test_rmse': 0.02240241421475168}, {'model': 'lasso', 'lag': 7, 'alpha': 1.0, 'test_rmse': 0.017810518698437194}, {'model': 'ridge', 'lag': 7, 'alpha': 1.0, 'test_rmse': 0.021354558617273457}, {'model': 'elastic_net', 'lag': 7, 'alpha': (0.1, 0.0), 'test_rmse': 0.017770587591394882}]\n",
      "[{'model': 'ols', 'lag': 10, 'alpha': None, 'test_rmse': 0.022604645838557265}, {'model': 'lasso', 'lag': 10, 'alpha': 1.0, 'test_rmse': 0.01782517652461829}, {'model': 'ridge', 'lag': 10, 'alpha': 1.0, 'test_rmse': 0.021500016416533478}, {'model': 'elastic_net', 'lag': 10, 'alpha': (0.1, 0.0), 'test_rmse': 0.017787119055585634}]\n",
      "[{'model': 'ols', 'lag': 14, 'alpha': None, 'test_rmse': 0.022396935324793775}, {'model': 'lasso', 'lag': 14, 'alpha': 1.0, 'test_rmse': 0.01784727262888585}, {'model': 'ridge', 'lag': 14, 'alpha': 1.0, 'test_rmse': 0.02129262556282986}, {'model': 'elastic_net', 'lag': 14, 'alpha': (0.1, 0.0), 'test_rmse': 0.017804842966696963}]\n",
      "[{'model': 'ols', 'lag': 20, 'alpha': None, 'test_rmse': 0.022817071800174386}, {'model': 'lasso', 'lag': 20, 'alpha': 1.0, 'test_rmse': 0.017848339348313397}, {'model': 'ridge', 'lag': 20, 'alpha': 1.0, 'test_rmse': 0.021635134054250306}, {'model': 'elastic_net', 'lag': 20, 'alpha': (0.1, 0.0), 'test_rmse': 0.0178086804453259}]\n",
      "[{'model': 'ols', 'lag': 21, 'alpha': None, 'test_rmse': 0.02288982313763762}, {'model': 'lasso', 'lag': 21, 'alpha': 1.0, 'test_rmse': 0.017854567880974535}, {'model': 'ridge', 'lag': 21, 'alpha': 1.0, 'test_rmse': 0.02169747914210556}, {'model': 'elastic_net', 'lag': 21, 'alpha': (0.1, 0.0), 'test_rmse': 0.017814868982324577}]\n",
      "[{'model': 'ols', 'lag': 22, 'alpha': None, 'test_rmse': 0.022759034109763716}, {'model': 'lasso', 'lag': 22, 'alpha': 1.0, 'test_rmse': 0.017860425125743845}, {'model': 'ridge', 'lag': 22, 'alpha': 1.0, 'test_rmse': 0.021618981260041876}, {'model': 'elastic_net', 'lag': 22, 'alpha': (0.1, 0.0), 'test_rmse': 0.017823638134598006}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.015582580994313821"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model:\n",
    "    \n",
    "    def get_target(self,df):\n",
    "        df['return'] = (df['f24'].shift(-78) - df['f24']) / df['f24']\n",
    "        df['return'] = df['return'].replace([np.inf,-np.inf],0)\n",
    "        return df[['return']]\n",
    "    \n",
    "    \n",
    "    def prepare_features(self, df):\n",
    "        \"\"\"\n",
    "        :param df: this is the data you want to use to prepare the features for your model\n",
    "        :return: X, a matrix of features (can be a numpy array or a pandas dataframe, your choice!)\n",
    "        \"\"\"\n",
    "        # todo: implement this function - you can use some of the features given to you or you can build a batch of\n",
    "        #  your own based on the data that you are given.\n",
    "        # *** PLEASE ENSURE THAT DO NOT INTRODUCE A LOOKAHEAD IN THIS MATRIX ***\n",
    "        # *** Bonus points for coding a function that tests against lookahead in X ***\n",
    "        \n",
    "        ## 1. Data Transformation\n",
    "#         return_type_columns = ['f0','f1','f2','f3','f11','f12']\n",
    "#         price_type_columns = ['f4', 'f5', 'f6', 'f7', 'f8', 'f9',\n",
    "#            'f10', 'f13', 'f16', 'f17', 'f18', 'f19',\n",
    "#            'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29',\n",
    "#            'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39',\n",
    "#            'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49',\n",
    "#            'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59',\n",
    "#            'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69',\n",
    "#            'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76']\n",
    "#         integer_type_columns = ['f14','f15','f77','f78']\n",
    "\n",
    "#         for col in price_type_columns:\n",
    "#             df[col] = (df[col] - df[col].shift(78))/df[col].shift(78)\n",
    "    \n",
    "#         for col in integer_type_columns:\n",
    "#             df[col] = (df[col] - df[col].shift(78))/df[col].shift(78)\n",
    "        \n",
    "        X = df\n",
    "        \n",
    "        # handle case of infinity    \n",
    "        X = X.replace([np.inf],1)\n",
    "        X = X.replace([-np.inf],-1)\n",
    "        \n",
    "        \n",
    "        ## 2. Drop highly correlated variables\n",
    "        X.drop(columns=['f5','f6','f7','f9','f8'],inplace=True)\n",
    "        X.drop(columns=['f25','f26','f28','f29','f31','f32','f34','f35'],inplace=True)\n",
    "        X.drop(columns=['f37','f38','f39','f42','f44','f45','f47','f48'],inplace=True)\n",
    "        X.drop(columns=['f51','f52','f54','f55','f57','f58','f60','f61'],inplace=True)\n",
    "        X.drop(columns=['f65','f64','f67','f63','f71','f70','f74','f73'],inplace=True)\n",
    "        \n",
    "        \n",
    "#         ## 3. Outlier Treatment\n",
    "#         window_size = 20*79  # 1 month (working days only) \n",
    "#         threshold = 2\n",
    "#         rolling_mean = X.rolling(window=window_size, min_periods=1).mean()\n",
    "#         rolling_std = X.rolling(window=window_size, min_periods=1).std()\n",
    "#         lower_bound = rolling_mean - threshold * rolling_std\n",
    "#         upper_bound = rolling_mean + threshold * rolling_std\n",
    "#         req_cols = list(X.columns)\n",
    "#         req_cols.remove('return')\n",
    "#         print(\"req_cols without 'return' \", req_cols)\n",
    "#         for column in req_cols:   \n",
    "#             X[column] = X[column].clip(lower=lower_bound[column], upper=upper_bound[column], axis=0)\n",
    "\n",
    "        # include lag column\n",
    "        column_name = 'return'\n",
    "        for i in range(1, self.lag + 1):\n",
    "            lagged_column_name = f'{column_name}_lag_{i}'\n",
    "            X[lagged_column_name] = X[column_name].shift(i*78)\n",
    "\n",
    "        # delete return columns\n",
    "        del X['return']\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    \n",
    "    def read_data(self,path_to_data):\n",
    "        data = pd.read_csv(path_to_data, index_col='time', parse_dates=['time'])\n",
    "        data.index = pd.to_datetime(data.index, format='%d-%m-%Y %H:%M')\n",
    "        data.sort_index(inplace=True)\n",
    "        data = data.fillna(method='ffill')\n",
    "        return data\n",
    "        \n",
    "    \n",
    "    def fit(self, path_to_train_csv, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        ### AG:  TASKS\n",
    "        ## Model Selection: \n",
    "            Linear: Base Model\n",
    "            Ridge : Handles Multicollinearity\n",
    "            RandomForest (large number of uncorrelated features, fail if the potential y values lie outside)\n",
    "            Time Series\n",
    "        ## Train-Test Split to get the optimal model\n",
    "        ## Train complete model\n",
    "        ## Store the optimal model\n",
    "        \"\"\"\n",
    "        \n",
    "        # get the values from kwargs\n",
    "        self.alphas = kwargs['alphas']\n",
    "        self.lag = kwargs['lag']\n",
    "        self.l1_ratio = kwargs['l1_ratio']\n",
    "        \n",
    "        \n",
    "        # todo: read train csv\n",
    "        # todo: do any operation you would like on it\n",
    "        self.train = self.read_data(path_to_train_csv)\n",
    "        \n",
    "        # todo: prepare features for the model fit\n",
    "        self.y = self.get_target(self.train)\n",
    "        self.X = self.prepare_features(self.train)        \n",
    "        \n",
    "        ## AG: Drop missing values\n",
    "        combined = pd.concat([self.X, self.y], axis=1)\n",
    "        combined_clean = combined.dropna()\n",
    "        self.X_clean = combined_clean.drop(columns='return')\n",
    "        self.y_clean = combined_clean['return']\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Sequential split into train, cv, and test sets\n",
    "        total_length = len(self.X_clean)\n",
    "        train_size = int(total_length * 0.8)  # 60% of data for training\n",
    "#         test_size = int(total_length * 0.2)     # 20% of data for cross-validation\n",
    "\n",
    "        X_train,y_train = self.X_clean[:train_size], self.y_clean[:train_size]\n",
    "        X_test,y_test = self.X_clean[train_size:], self.y_clean[train_size:]\n",
    "\n",
    "        \n",
    "        \n",
    "        # Range of hyperparameters to test for Lasso, Ridge, and Elastic Net\n",
    "        best_alpha = None\n",
    "        lowest_cv_rmse = float('inf')\n",
    "        best_model = None\n",
    "        lowest_rmse = float('inf')\n",
    "        best_model_name = None\n",
    "        \n",
    "        res_list = []\n",
    "        \n",
    "        for model_type in args:\n",
    "            if model_type == 'ols':\n",
    "                model = LinearRegression()\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "#                 print(y_pred)\n",
    "#                 print(y_test)\n",
    "                test_rmse = get_rmse(y_test,y_pred)\n",
    "                res_list.append({'model':model_type,'lag':self.lag,'alpha':None,'test_rmse':test_rmse})\n",
    "                \n",
    "                if test_rmse<lowest_rmse:\n",
    "                    lowest_rmse = test_rmse\n",
    "                    best_model = model\n",
    "                    best_model_name = model_type\n",
    "                    \n",
    "            else:\n",
    "                total_length = len(X_train)\n",
    "                train_size = int(total_length * 0.8)\n",
    "                X_train_fold,y_train_fold = X_train[:train_size], y_train[:train_size]\n",
    "                X_cv_fold,y_cv_fold = X_train[train_size:], y_train[train_size:]\n",
    "\n",
    "                # test for lasso model\n",
    "                if model_type=='lasso':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    for alpha in self.alphas:\n",
    "                        model = Lasso(alpha=alpha)\n",
    "                        model.fit(X_train_fold,y_train_fold)\n",
    "                        y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                        non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                        y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                        cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                         print(\"model: {}, alpha: {}, cv_rmse: {}\".format(model_type,alpha,cv_rmse))\n",
    "                        if cv_rmse<lowest_cv_rmse:\n",
    "                            best_alpha = alpha\n",
    "                            lowest_cv_rmse = cv_rmse\n",
    "                    \n",
    "                    # get the test_rmse for the model\n",
    "                    model = Lasso(alpha=best_alpha)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "                    \n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':best_alpha,'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "\n",
    "            \n",
    "                # test for ridge model\n",
    "                if model_type=='ridge':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    for alpha in self.alphas:\n",
    "                        model = Ridge(alpha=alpha)\n",
    "                        model.fit(X_train_fold,y_train_fold)\n",
    "                        y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                        non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                        y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                        cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                         print(\"model: {}, alpha: {}, cv_rmse: {}\".format(model_type,alpha,cv_rmse))\n",
    "                        if cv_rmse<lowest_cv_rmse:\n",
    "                            best_alpha = alpha\n",
    "                            lowest_cv_rmse = cv_rmse\n",
    "                    \n",
    "                    # get the test_rmse for the model\n",
    "                    model = Ridge(alpha=best_alpha)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "                    \n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':best_alpha,'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "\n",
    "                        \n",
    "                        \n",
    "                # test for ridge model\n",
    "                if model_type=='elastic_net':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    best_l1_ratio = 0\n",
    "                    for alpha in self.alphas:\n",
    "                        for l1_ratio in self.l1_ratio:\n",
    "                            model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "                            model.fit(X_train_fold,y_train_fold)\n",
    "                            y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                            non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                            y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                            cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                             print(\"model: {}, alpha: {}, l1_ratio: {},cv_rmse: {}\".format(model_type,alpha,l1_ratio,cv_rmse))\n",
    "                            if cv_rmse<lowest_cv_rmse:\n",
    "                                best_alpha = alpha\n",
    "                                best_l1_ratio = l1_ratio\n",
    "                                lowest_cv_rmse = cv_rmse\n",
    "\n",
    "                    # get the test_rmse for the model\n",
    "                    model = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "\n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':(best_alpha,best_l1_ratio),'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "        \n",
    "    \n",
    "        self.model = best_model\n",
    "        self.model_name = best_model_name\n",
    "        self.res_list = res_list\n",
    "        return self\n",
    "\n",
    "\n",
    "    \n",
    "    def predict(self, path_to_test_csv, *args, **kwargs):\n",
    "        # todo: read test csv\n",
    "        # todo: do any operation you would like on it\n",
    "        self.test = pd.read_csv(path_to_test_csv, index_col='time', parse_dates=['time'])\n",
    "        self.test.index = pd.to_datetime(self.test.index, format='%d-%m-%Y %H:%M')\n",
    "        self.test.sort_index(inplace=True)\n",
    "        self.test = self.test.fillna(method='ffill')\n",
    "    \n",
    "        # todo: prepare features for the model predict\n",
    "        self.y_test = self.get_target(self.test)\n",
    "        self.X_test = self.prepare_features(self.test)\n",
    "        \n",
    "\n",
    "        # todo: calculate your model prediction (call it ypred) using X and any other information you want to use\n",
    "        ypred = pd.Series(np.nan, index=self.X_test.index)\n",
    "        non_nan_rows = ~self.X_test.isnull().any(axis=1)\n",
    "        ypred[non_nan_rows] = self.model.predict(self.X_test[non_nan_rows])\n",
    "\n",
    "        # this follows the scikit-learn pattern by returning ypred\n",
    "        return ypred\n",
    "\n",
    "def get_rmse(ypred,ytest):\n",
    "    combined = pd.concat([ypred, ytest], axis=1)\n",
    "    combined_clean = combined.dropna()\n",
    "    \n",
    "    rmse_ = rmse(combined_clean[0],combined_clean['return'])\n",
    "    return rmse_\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "train_csv_path = '../data/train.csv'\n",
    "test_csv_path = '../data/test.csv'\n",
    "\n",
    "fit_args = ['ols','lasso','ridge','elastic_net']  # todo: populate this as you see fit\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "for l in [0,1,3,5,7,10,14,20,21,22]:\n",
    "    fit_kwargs = {'alphas':np.linspace(0,1,11),'lag':l,'l1_ratio':np.linspace(0,1,11)} # todo: populate this as you see fit\n",
    "    clf = Model()\n",
    "    clf.fit(train_csv_path, *fit_args, **fit_kwargs)\n",
    "    result_df = pd.concat([result_df,pd.DataFrame(clf.res_list)])\n",
    "    print(clf.res_list)\n",
    "\n",
    "result_df.to_csv('result_sel_no_fe_no_out.csv')\n",
    "\n",
    "predict_args = []  # todo: populate this as you see fit\n",
    "predict_kwargs = {}  # todo: populate this as you see fit\n",
    "ypred = clf.predict(test_csv_path, *predict_args, **predict_kwargs)\n",
    "get_rmse(ypred, clf.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fd999b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ElasticNet(alpha=0.1, l1_ratio=0.0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet(alpha=0.1, l1_ratio=0.0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ElasticNet(alpha=0.1, l1_ratio=0.0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de58c69",
   "metadata": {},
   "source": [
    "# Trial 5: Selected Variables + No Feature Engineering + Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94b90550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 0, 'alpha': None, 'test_rmse': 0.025536156059390018}, {'model': 'lasso', 'lag': 0, 'alpha': 0.0, 'test_rmse': 0.02553615605942019}, {'model': 'ridge', 'lag': 0, 'alpha': 1.0, 'test_rmse': 0.024046808863779832}, {'model': 'elastic_net', 'lag': 0, 'alpha': (0.0, 0.0), 'test_rmse': 0.02553615605942019}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 1, 'alpha': None, 'test_rmse': 0.02584735065486849}, {'model': 'lasso', 'lag': 1, 'alpha': 0.0, 'test_rmse': 0.025847350654799955}, {'model': 'ridge', 'lag': 1, 'alpha': 1.0, 'test_rmse': 0.02422881403889318}, {'model': 'elastic_net', 'lag': 1, 'alpha': (0.1, 0.0), 'test_rmse': 0.017826790790423954}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 3, 'alpha': None, 'test_rmse': 0.02640356091009466}, {'model': 'lasso', 'lag': 3, 'alpha': 1.0, 'test_rmse': 0.0178131377448498}, {'model': 'ridge', 'lag': 3, 'alpha': 1.0, 'test_rmse': 0.024543359895066348}, {'model': 'elastic_net', 'lag': 3, 'alpha': (0.1, 0.0), 'test_rmse': 0.017838937922928}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 5, 'alpha': None, 'test_rmse': 0.026310154371916767}, {'model': 'lasso', 'lag': 5, 'alpha': 1.0, 'test_rmse': 0.01780593886897878}, {'model': 'ridge', 'lag': 5, 'alpha': 1.0, 'test_rmse': 0.024315043180406865}, {'model': 'elastic_net', 'lag': 5, 'alpha': (0.1, 0.0), 'test_rmse': 0.01783334446150154}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 7, 'alpha': None, 'test_rmse': 0.0262469771755019}, {'model': 'lasso', 'lag': 7, 'alpha': 1.0, 'test_rmse': 0.017819112246861907}, {'model': 'ridge', 'lag': 7, 'alpha': 1.0, 'test_rmse': 0.02419979258258249}, {'model': 'elastic_net', 'lag': 7, 'alpha': (0.1, 0.0), 'test_rmse': 0.017848326649073844}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 10, 'alpha': None, 'test_rmse': 0.026517858861989707}, {'model': 'lasso', 'lag': 10, 'alpha': 1.0, 'test_rmse': 0.017833850675140827}, {'model': 'ridge', 'lag': 10, 'alpha': 1.0, 'test_rmse': 0.02436602590949519}, {'model': 'elastic_net', 'lag': 10, 'alpha': (0.1, 0.0), 'test_rmse': 0.01786593565491047}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 14, 'alpha': None, 'test_rmse': 0.026209687291962176}, {'model': 'lasso', 'lag': 14, 'alpha': 1.0, 'test_rmse': 0.017855216432787886}, {'model': 'ridge', 'lag': 14, 'alpha': 1.0, 'test_rmse': 0.024050235510467675}, {'model': 'elastic_net', 'lag': 14, 'alpha': (0.1, 0.0), 'test_rmse': 0.017883205349768266}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 20, 'alpha': None, 'test_rmse': 0.02656114453915851}, {'model': 'lasso', 'lag': 20, 'alpha': 1.0, 'test_rmse': 0.017857191926209985}, {'model': 'ridge', 'lag': 20, 'alpha': 1.0, 'test_rmse': 0.024395464625164624}, {'model': 'elastic_net', 'lag': 20, 'alpha': (0.1, 0.0), 'test_rmse': 0.017886236123837457}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 21, 'alpha': None, 'test_rmse': 0.02662249772476953}, {'model': 'lasso', 'lag': 21, 'alpha': 1.0, 'test_rmse': 0.017863450307422826}, {'model': 'ridge', 'lag': 21, 'alpha': 1.0, 'test_rmse': 0.0244534810574653}, {'model': 'elastic_net', 'lag': 21, 'alpha': (0.1, 0.0), 'test_rmse': 0.017892463967499595}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 22, 'alpha': None, 'test_rmse': 0.026498081670471164}, {'model': 'lasso', 'lag': 22, 'alpha': 1.0, 'test_rmse': 0.017869607558401963}, {'model': 'ridge', 'lag': 22, 'alpha': 1.0, 'test_rmse': 0.02438198771944038}, {'model': 'elastic_net', 'lag': 22, 'alpha': (0.1, 0.0), 'test_rmse': 0.01790134349023232}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.015473652258366286"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model:\n",
    "    \n",
    "    def get_target(self,df):\n",
    "        df['return'] = (df['f24'].shift(-78) - df['f24']) / df['f24']\n",
    "        df['return'] = df['return'].replace([np.inf,-np.inf],0)\n",
    "        return df[['return']]\n",
    "    \n",
    "    \n",
    "    def prepare_features(self, df):\n",
    "        \"\"\"\n",
    "        :param df: this is the data you want to use to prepare the features for your model\n",
    "        :return: X, a matrix of features (can be a numpy array or a pandas dataframe, your choice!)\n",
    "        \"\"\"\n",
    "        # todo: implement this function - you can use some of the features given to you or you can build a batch of\n",
    "        #  your own based on the data that you are given.\n",
    "        # *** PLEASE ENSURE THAT DO NOT INTRODUCE A LOOKAHEAD IN THIS MATRIX ***\n",
    "        # *** Bonus points for coding a function that tests against lookahead in X ***\n",
    "        \n",
    "        ## 1. Data Transformation\n",
    "#         return_type_columns = ['f0','f1','f2','f3','f11','f12']\n",
    "#         price_type_columns = ['f4', 'f5', 'f6', 'f7', 'f8', 'f9',\n",
    "#            'f10', 'f13', 'f16', 'f17', 'f18', 'f19',\n",
    "#            'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29',\n",
    "#            'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39',\n",
    "#            'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49',\n",
    "#            'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59',\n",
    "#            'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69',\n",
    "#            'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76']\n",
    "#         integer_type_columns = ['f14','f15','f77','f78']\n",
    "\n",
    "#         for col in price_type_columns:\n",
    "#             df[col] = (df[col] - df[col].shift(78))/df[col].shift(78)\n",
    "    \n",
    "#         for col in integer_type_columns:\n",
    "#             df[col] = (df[col] - df[col].shift(78))/df[col].shift(78)\n",
    "        \n",
    "        X = df\n",
    "        \n",
    "        # handle case of infinity    \n",
    "        X = X.replace([np.inf],1)\n",
    "        X = X.replace([-np.inf],-1)\n",
    "        \n",
    "        \n",
    "        ## 2. Drop highly correlated variables\n",
    "        X.drop(columns=['f5','f6','f7','f9','f8'],inplace=True)\n",
    "        X.drop(columns=['f25','f26','f28','f29','f31','f32','f34','f35'],inplace=True)\n",
    "        X.drop(columns=['f37','f38','f39','f42','f44','f45','f47','f48'],inplace=True)\n",
    "        X.drop(columns=['f51','f52','f54','f55','f57','f58','f60','f61'],inplace=True)\n",
    "        X.drop(columns=['f65','f64','f67','f63','f71','f70','f74','f73'],inplace=True)\n",
    "        \n",
    "        \n",
    "        ## 3. Outlier Treatment\n",
    "        window_size = 20*79  # 1 month (working days only) \n",
    "        threshold = 2\n",
    "        rolling_mean = X.rolling(window=window_size, min_periods=1).mean()\n",
    "        rolling_std = X.rolling(window=window_size, min_periods=1).std()\n",
    "        lower_bound = rolling_mean - threshold * rolling_std\n",
    "        upper_bound = rolling_mean + threshold * rolling_std\n",
    "        req_cols = list(X.columns)\n",
    "        req_cols.remove('return')\n",
    "        print(\"req_cols without 'return' \", req_cols)\n",
    "        for column in req_cols:   \n",
    "            X[column] = X[column].clip(lower=lower_bound[column], upper=upper_bound[column], axis=0)\n",
    "\n",
    "        # include lag column\n",
    "        column_name = 'return'\n",
    "        for i in range(1, self.lag + 1):\n",
    "            lagged_column_name = f'{column_name}_lag_{i}'\n",
    "            X[lagged_column_name] = X[column_name].shift(i*78)\n",
    "\n",
    "        # delete return columns\n",
    "        del X['return']\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    \n",
    "    def read_data(self,path_to_data):\n",
    "        data = pd.read_csv(path_to_data, index_col='time', parse_dates=['time'])\n",
    "        data.index = pd.to_datetime(data.index, format='%d-%m-%Y %H:%M')\n",
    "        data.sort_index(inplace=True)\n",
    "        data = data.fillna(method='ffill')\n",
    "        return data\n",
    "        \n",
    "    \n",
    "    def fit(self, path_to_train_csv, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        ### AG:  TASKS\n",
    "        ## Model Selection: \n",
    "            Linear: Base Model\n",
    "            Ridge : Handles Multicollinearity\n",
    "            RandomForest (large number of uncorrelated features, fail if the potential y values lie outside)\n",
    "            Time Series\n",
    "        ## Train-Test Split to get the optimal model\n",
    "        ## Train complete model\n",
    "        ## Store the optimal model\n",
    "        \"\"\"\n",
    "        \n",
    "        # get the values from kwargs\n",
    "        self.alphas = kwargs['alphas']\n",
    "        self.lag = kwargs['lag']\n",
    "        self.l1_ratio = kwargs['l1_ratio']\n",
    "        \n",
    "        \n",
    "        # todo: read train csv\n",
    "        # todo: do any operation you would like on it\n",
    "        self.train = self.read_data(path_to_train_csv)\n",
    "        \n",
    "        # todo: prepare features for the model fit\n",
    "        self.y = self.get_target(self.train)\n",
    "        self.X = self.prepare_features(self.train)        \n",
    "        \n",
    "        ## AG: Drop missing values\n",
    "        combined = pd.concat([self.X, self.y], axis=1)\n",
    "        combined_clean = combined.dropna()\n",
    "        self.X_clean = combined_clean.drop(columns='return')\n",
    "        self.y_clean = combined_clean['return']\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Sequential split into train, cv, and test sets\n",
    "        total_length = len(self.X_clean)\n",
    "        train_size = int(total_length * 0.8)  # 60% of data for training\n",
    "#         test_size = int(total_length * 0.2)     # 20% of data for cross-validation\n",
    "\n",
    "        X_train,y_train = self.X_clean[:train_size], self.y_clean[:train_size]\n",
    "        X_test,y_test = self.X_clean[train_size:], self.y_clean[train_size:]\n",
    "\n",
    "        \n",
    "        \n",
    "        # Range of hyperparameters to test for Lasso, Ridge, and Elastic Net\n",
    "        best_alpha = None\n",
    "        lowest_cv_rmse = float('inf')\n",
    "        best_model = None\n",
    "        lowest_rmse = float('inf')\n",
    "        best_model_name = None\n",
    "        \n",
    "        res_list = []\n",
    "        \n",
    "        for model_type in args:\n",
    "            if model_type == 'ols':\n",
    "                model = LinearRegression()\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "#                 print(y_pred)\n",
    "#                 print(y_test)\n",
    "                test_rmse = get_rmse(y_test,y_pred)\n",
    "                res_list.append({'model':model_type,'lag':self.lag,'alpha':None,'test_rmse':test_rmse})\n",
    "                \n",
    "                if test_rmse<lowest_rmse:\n",
    "                    lowest_rmse = test_rmse\n",
    "                    best_model = model\n",
    "                    best_model_name = model_type\n",
    "                    \n",
    "            else:\n",
    "                total_length = len(X_train)\n",
    "                train_size = int(total_length * 0.8)\n",
    "                X_train_fold,y_train_fold = X_train[:train_size], y_train[:train_size]\n",
    "                X_cv_fold,y_cv_fold = X_train[train_size:], y_train[train_size:]\n",
    "\n",
    "                # test for lasso model\n",
    "                if model_type=='lasso':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    for alpha in self.alphas:\n",
    "                        model = Lasso(alpha=alpha)\n",
    "                        model.fit(X_train_fold,y_train_fold)\n",
    "                        y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                        non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                        y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                        cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                         print(\"model: {}, alpha: {}, cv_rmse: {}\".format(model_type,alpha,cv_rmse))\n",
    "                        if cv_rmse<lowest_cv_rmse:\n",
    "                            best_alpha = alpha\n",
    "                            lowest_cv_rmse = cv_rmse\n",
    "                    \n",
    "                    # get the test_rmse for the model\n",
    "                    model = Lasso(alpha=best_alpha)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "                    \n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':best_alpha,'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "\n",
    "            \n",
    "                # test for ridge model\n",
    "                if model_type=='ridge':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    for alpha in self.alphas:\n",
    "                        model = Ridge(alpha=alpha)\n",
    "                        model.fit(X_train_fold,y_train_fold)\n",
    "                        y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                        non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                        y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                        cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                         print(\"model: {}, alpha: {}, cv_rmse: {}\".format(model_type,alpha,cv_rmse))\n",
    "                        if cv_rmse<lowest_cv_rmse:\n",
    "                            best_alpha = alpha\n",
    "                            lowest_cv_rmse = cv_rmse\n",
    "                    \n",
    "                    # get the test_rmse for the model\n",
    "                    model = Ridge(alpha=best_alpha)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "                    \n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':best_alpha,'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "\n",
    "                        \n",
    "                        \n",
    "                # test for ridge model\n",
    "                if model_type=='elastic_net':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    best_l1_ratio = 0\n",
    "                    for alpha in self.alphas:\n",
    "                        for l1_ratio in self.l1_ratio:\n",
    "                            model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "                            model.fit(X_train_fold,y_train_fold)\n",
    "                            y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                            non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                            y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                            cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                             print(\"model: {}, alpha: {}, l1_ratio: {},cv_rmse: {}\".format(model_type,alpha,l1_ratio,cv_rmse))\n",
    "                            if cv_rmse<lowest_cv_rmse:\n",
    "                                best_alpha = alpha\n",
    "                                best_l1_ratio = l1_ratio\n",
    "                                lowest_cv_rmse = cv_rmse\n",
    "\n",
    "                    # get the test_rmse for the model\n",
    "                    model = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "\n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':(best_alpha,best_l1_ratio),'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "        \n",
    "    \n",
    "        self.model = best_model\n",
    "        self.model_name = best_model_name\n",
    "        self.res_list = res_list\n",
    "        return self\n",
    "\n",
    "\n",
    "    \n",
    "    def predict(self, path_to_test_csv, *args, **kwargs):\n",
    "        # todo: read test csv\n",
    "        # todo: do any operation you would like on it\n",
    "        self.test = pd.read_csv(path_to_test_csv, index_col='time', parse_dates=['time'])\n",
    "        self.test.index = pd.to_datetime(self.test.index, format='%d-%m-%Y %H:%M')\n",
    "        self.test.sort_index(inplace=True)\n",
    "        self.test = self.test.fillna(method='ffill')\n",
    "    \n",
    "        # todo: prepare features for the model predict\n",
    "        self.y_test = self.get_target(self.test)\n",
    "        self.X_test = self.prepare_features(self.test)\n",
    "        \n",
    "\n",
    "        # todo: calculate your model prediction (call it ypred) using X and any other information you want to use\n",
    "        ypred = pd.Series(np.nan, index=self.X_test.index)\n",
    "        non_nan_rows = ~self.X_test.isnull().any(axis=1)\n",
    "        ypred[non_nan_rows] = self.model.predict(self.X_test[non_nan_rows])\n",
    "\n",
    "        # this follows the scikit-learn pattern by returning ypred\n",
    "        return ypred\n",
    "\n",
    "def get_rmse(ypred,ytest):\n",
    "    combined = pd.concat([ypred, ytest], axis=1)\n",
    "    combined_clean = combined.dropna()\n",
    "    \n",
    "    rmse_ = rmse(combined_clean[0],combined_clean['return'])\n",
    "    return rmse_\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "train_csv_path = '../data/train.csv'\n",
    "test_csv_path = '../data/test.csv'\n",
    "\n",
    "fit_args = ['ols','lasso','ridge','elastic_net']  # todo: populate this as you see fit\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "for l in [0,1,3,5,7,10,14,20,21,22]:\n",
    "    fit_kwargs = {'alphas':np.linspace(0,1,11),'lag':l,'l1_ratio':np.linspace(0,1,11)} # todo: populate this as you see fit\n",
    "    clf = Model()\n",
    "    clf.fit(train_csv_path, *fit_args, **fit_kwargs)\n",
    "    result_df = pd.concat([result_df,pd.DataFrame(clf.res_list)])\n",
    "    print(clf.res_list)\n",
    "\n",
    "result_df.to_csv('result_sel_no_fe_out.csv')\n",
    "\n",
    "predict_args = []  # todo: populate this as you see fit\n",
    "predict_kwargs = {}  # todo: populate this as you see fit\n",
    "ypred = clf.predict(test_csv_path, *predict_args, **predict_kwargs)\n",
    "get_rmse(ypred, clf.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce81b9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9f1523",
   "metadata": {},
   "source": [
    "# Trial 5: Selected Variables + Feature Engineering + No Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5aacbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'model': 'ols', 'lag': 0, 'alpha': None, 'test_rmse': 0.017588627606298132}, {'model': 'lasso', 'lag': 0, 'alpha': 0.1, 'test_rmse': 0.01782621513129384}, {'model': 'ridge', 'lag': 0, 'alpha': 1.0, 'test_rmse': 0.01758987546100869}, {'model': 'elastic_net', 'lag': 0, 'alpha': (0.1, 0.0), 'test_rmse': 0.01779601447019981}]\n",
      "[{'model': 'ols', 'lag': 1, 'alpha': None, 'test_rmse': 0.01758862760629818}, {'model': 'lasso', 'lag': 1, 'alpha': 0.1, 'test_rmse': 0.01782621513129384}, {'model': 'ridge', 'lag': 1, 'alpha': 1.0, 'test_rmse': 0.017588597103686664}, {'model': 'elastic_net', 'lag': 1, 'alpha': (0.1, 0.0), 'test_rmse': 0.01779602529883987}]\n",
      "[{'model': 'ols', 'lag': 3, 'alpha': None, 'test_rmse': 0.017579437519140106}, {'model': 'lasso', 'lag': 3, 'alpha': 0.1, 'test_rmse': 0.017834525958684237}, {'model': 'ridge', 'lag': 3, 'alpha': 1.0, 'test_rmse': 0.017583510955938773}, {'model': 'elastic_net', 'lag': 3, 'alpha': (0.1, 0.0), 'test_rmse': 0.017804969253234458}]\n",
      "[{'model': 'ols', 'lag': 5, 'alpha': None, 'test_rmse': 0.01751745321609229}, {'model': 'lasso', 'lag': 5, 'alpha': 0.1, 'test_rmse': 0.017845020728303216}, {'model': 'ridge', 'lag': 5, 'alpha': 1.0, 'test_rmse': 0.017524792457378164}, {'model': 'elastic_net', 'lag': 5, 'alpha': (0.1, 0.0), 'test_rmse': 0.017818079991272464}]\n",
      "[{'model': 'ols', 'lag': 7, 'alpha': None, 'test_rmse': 0.017510319370655586}, {'model': 'lasso', 'lag': 7, 'alpha': 0.1, 'test_rmse': 0.017853066743560787}, {'model': 'ridge', 'lag': 7, 'alpha': 1.0, 'test_rmse': 0.01751755458133183}, {'model': 'elastic_net', 'lag': 7, 'alpha': (0.1, 0.0), 'test_rmse': 0.017829437936908967}]\n",
      "[{'model': 'ols', 'lag': 10, 'alpha': None, 'test_rmse': 0.017608966828171885}, {'model': 'lasso', 'lag': 10, 'alpha': 0.1, 'test_rmse': 0.017873115564181}, {'model': 'ridge', 'lag': 10, 'alpha': 1.0, 'test_rmse': 0.017605505290852797}, {'model': 'elastic_net', 'lag': 10, 'alpha': (0.1, 0.0), 'test_rmse': 0.01785176746415099}]\n",
      "[{'model': 'ols', 'lag': 14, 'alpha': None, 'test_rmse': 0.017593505534180254}, {'model': 'lasso', 'lag': 14, 'alpha': 0.1, 'test_rmse': 0.017872727806492694}, {'model': 'ridge', 'lag': 14, 'alpha': 1.0, 'test_rmse': 0.01758590991075766}, {'model': 'elastic_net', 'lag': 14, 'alpha': (0.1, 0.0), 'test_rmse': 0.01783556574466215}]\n",
      "[{'model': 'ols', 'lag': 20, 'alpha': None, 'test_rmse': 0.017530683393454694}, {'model': 'lasso', 'lag': 20, 'alpha': 0.1, 'test_rmse': 0.017899092206831904}, {'model': 'ridge', 'lag': 20, 'alpha': 1.0, 'test_rmse': 0.017524495805291793}, {'model': 'elastic_net', 'lag': 20, 'alpha': (0.1, 0.0), 'test_rmse': 0.01786497932377147}]\n",
      "[{'model': 'ols', 'lag': 21, 'alpha': None, 'test_rmse': 0.017537010667608134}, {'model': 'lasso', 'lag': 21, 'alpha': 0.1, 'test_rmse': 0.01789922450465425}, {'model': 'ridge', 'lag': 21, 'alpha': 1.0, 'test_rmse': 0.017529850874395066}, {'model': 'elastic_net', 'lag': 21, 'alpha': (0.1, 0.0), 'test_rmse': 0.0178670299774759}]\n",
      "[{'model': 'ols', 'lag': 22, 'alpha': None, 'test_rmse': 0.01758447130527933}, {'model': 'lasso', 'lag': 22, 'alpha': 0.1, 'test_rmse': 0.01789691999641647}, {'model': 'ridge', 'lag': 22, 'alpha': 1.0, 'test_rmse': 0.01757167841349979}, {'model': 'elastic_net', 'lag': 22, 'alpha': (0.1, 0.0), 'test_rmse': 0.017868559768898767}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.015807069286067725"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model:\n",
    "    \n",
    "    def get_target(self,df):\n",
    "        df['return'] = (df['f24'].shift(-78) - df['f24']) / df['f24']\n",
    "        df['return'] = df['return'].replace([np.inf,-np.inf],0)\n",
    "        return df[['return']]\n",
    "    \n",
    "    \n",
    "    def prepare_features(self, df):\n",
    "        \"\"\"\n",
    "        :param df: this is the data you want to use to prepare the features for your model\n",
    "        :return: X, a matrix of features (can be a numpy array or a pandas dataframe, your choice!)\n",
    "        \"\"\"\n",
    "        # todo: implement this function - you can use some of the features given to you or you can build a batch of\n",
    "        #  your own based on the data that you are given.\n",
    "        # *** PLEASE ENSURE THAT DO NOT INTRODUCE A LOOKAHEAD IN THIS MATRIX ***\n",
    "        # *** Bonus points for coding a function that tests against lookahead in X ***\n",
    "        \n",
    "        ## 1. Data Transformation\n",
    "        return_type_columns = ['f0','f1','f2','f3','f11','f12']\n",
    "        price_type_columns = ['f4', 'f5', 'f6', 'f7', 'f8', 'f9',\n",
    "           'f10', 'f13', 'f16', 'f17', 'f18', 'f19',\n",
    "           'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29',\n",
    "           'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39',\n",
    "           'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49',\n",
    "           'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59',\n",
    "           'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69',\n",
    "           'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76']\n",
    "        integer_type_columns = ['f14','f15','f77','f78']\n",
    "\n",
    "        for col in price_type_columns:\n",
    "            df[col] = (df[col] - df[col].shift(78))/df[col].shift(78)\n",
    "    \n",
    "        for col in integer_type_columns:\n",
    "            df[col] = (df[col] - df[col].shift(78))/df[col].shift(78)\n",
    "        \n",
    "        X = df\n",
    "        \n",
    "        # handle case of infinity    \n",
    "        X = X.replace([np.inf],1)\n",
    "        X = X.replace([-np.inf],-1)\n",
    "        \n",
    "        \n",
    "        ## 2. Drop highly correlated variables\n",
    "        X.drop(columns=['f5','f6','f7','f9','f8'],inplace=True)\n",
    "        X.drop(columns=['f25','f26','f28','f29','f31','f32','f34','f35'],inplace=True)\n",
    "        X.drop(columns=['f37','f38','f39','f42','f44','f45','f47','f48'],inplace=True)\n",
    "        X.drop(columns=['f51','f52','f54','f55','f57','f58','f60','f61'],inplace=True)\n",
    "        X.drop(columns=['f65','f64','f67','f63','f71','f70','f74','f73'],inplace=True)\n",
    "        \n",
    "        \n",
    "#         ## 3. Outlier Treatment\n",
    "#         window_size = 20*79  # 1 month (working days only) \n",
    "#         threshold = 2\n",
    "#         rolling_mean = X.rolling(window=window_size, min_periods=1).mean()\n",
    "#         rolling_std = X.rolling(window=window_size, min_periods=1).std()\n",
    "#         lower_bound = rolling_mean - threshold * rolling_std\n",
    "#         upper_bound = rolling_mean + threshold * rolling_std\n",
    "#         req_cols = list(X.columns)\n",
    "#         req_cols.remove('return')\n",
    "#         print(\"req_cols without 'return' \", req_cols)\n",
    "#         for column in req_cols:   \n",
    "#             X[column] = X[column].clip(lower=lower_bound[column], upper=upper_bound[column], axis=0)\n",
    "\n",
    "        # include lag column\n",
    "        column_name = 'return'\n",
    "        for i in range(1, self.lag + 1):\n",
    "            lagged_column_name = f'{column_name}_lag_{i}'\n",
    "            X[lagged_column_name] = X[column_name].shift(i*78)\n",
    "\n",
    "        # delete return columns\n",
    "        del X['return']\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    \n",
    "    def read_data(self,path_to_data):\n",
    "        data = pd.read_csv(path_to_data, index_col='time', parse_dates=['time'])\n",
    "        data.index = pd.to_datetime(data.index, format='%d-%m-%Y %H:%M')\n",
    "        data.sort_index(inplace=True)\n",
    "        data = data.fillna(method='ffill')\n",
    "        return data\n",
    "        \n",
    "    \n",
    "    def fit(self, path_to_train_csv, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        ### AG:  TASKS\n",
    "        ## Model Selection: \n",
    "            Linear: Base Model\n",
    "            Ridge : Handles Multicollinearity\n",
    "            RandomForest (large number of uncorrelated features, fail if the potential y values lie outside)\n",
    "            Time Series\n",
    "        ## Train-Test Split to get the optimal model\n",
    "        ## Train complete model\n",
    "        ## Store the optimal model\n",
    "        \"\"\"\n",
    "        \n",
    "        # get the values from kwargs\n",
    "        self.alphas = kwargs['alphas']\n",
    "        self.lag = kwargs['lag']\n",
    "        self.l1_ratio = kwargs['l1_ratio']\n",
    "        \n",
    "        \n",
    "        # todo: read train csv\n",
    "        # todo: do any operation you would like on it\n",
    "        self.train = self.read_data(path_to_train_csv)\n",
    "        \n",
    "        # todo: prepare features for the model fit\n",
    "        self.y = self.get_target(self.train)\n",
    "        self.X = self.prepare_features(self.train)        \n",
    "        \n",
    "        ## AG: Drop missing values\n",
    "        combined = pd.concat([self.X, self.y], axis=1)\n",
    "        combined_clean = combined.dropna()\n",
    "        self.X_clean = combined_clean.drop(columns='return')\n",
    "        self.y_clean = combined_clean['return']\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Sequential split into train, cv, and test sets\n",
    "        total_length = len(self.X_clean)\n",
    "        train_size = int(total_length * 0.8)  # 60% of data for training\n",
    "#         test_size = int(total_length * 0.2)     # 20% of data for cross-validation\n",
    "\n",
    "        X_train,y_train = self.X_clean[:train_size], self.y_clean[:train_size]\n",
    "        X_test,y_test = self.X_clean[train_size:], self.y_clean[train_size:]\n",
    "\n",
    "        \n",
    "        \n",
    "        # Range of hyperparameters to test for Lasso, Ridge, and Elastic Net\n",
    "        best_alpha = None\n",
    "        lowest_cv_rmse = float('inf')\n",
    "        best_model = None\n",
    "        lowest_rmse = float('inf')\n",
    "        best_model_name = None\n",
    "        \n",
    "        res_list = []\n",
    "        \n",
    "        for model_type in args:\n",
    "            if model_type == 'ols':\n",
    "                model = LinearRegression()\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "#                 print(y_pred)\n",
    "#                 print(y_test)\n",
    "                test_rmse = get_rmse(y_test,y_pred)\n",
    "                res_list.append({'model':model_type,'lag':self.lag,'alpha':None,'test_rmse':test_rmse})\n",
    "                \n",
    "                if test_rmse<lowest_rmse:\n",
    "                    lowest_rmse = test_rmse\n",
    "                    best_model = model\n",
    "                    best_model_name = model_type\n",
    "                    \n",
    "            else:\n",
    "                total_length = len(X_train)\n",
    "                train_size = int(total_length * 0.8)\n",
    "                X_train_fold,y_train_fold = X_train[:train_size], y_train[:train_size]\n",
    "                X_cv_fold,y_cv_fold = X_train[train_size:], y_train[train_size:]\n",
    "\n",
    "                # test for lasso model\n",
    "                if model_type=='lasso':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    for alpha in self.alphas:\n",
    "                        model = Lasso(alpha=alpha)\n",
    "                        model.fit(X_train_fold,y_train_fold)\n",
    "                        y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                        non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                        y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                        cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                         print(\"model: {}, alpha: {}, cv_rmse: {}\".format(model_type,alpha,cv_rmse))\n",
    "                        if cv_rmse<lowest_cv_rmse:\n",
    "                            best_alpha = alpha\n",
    "                            lowest_cv_rmse = cv_rmse\n",
    "                    \n",
    "                    # get the test_rmse for the model\n",
    "                    model = Lasso(alpha=best_alpha)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "                    \n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':best_alpha,'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "\n",
    "            \n",
    "                # test for ridge model\n",
    "                if model_type=='ridge':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    for alpha in self.alphas:\n",
    "                        model = Ridge(alpha=alpha)\n",
    "                        model.fit(X_train_fold,y_train_fold)\n",
    "                        y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                        non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                        y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                        cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                         print(\"model: {}, alpha: {}, cv_rmse: {}\".format(model_type,alpha,cv_rmse))\n",
    "                        if cv_rmse<lowest_cv_rmse:\n",
    "                            best_alpha = alpha\n",
    "                            lowest_cv_rmse = cv_rmse\n",
    "                    \n",
    "                    # get the test_rmse for the model\n",
    "                    model = Ridge(alpha=best_alpha)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "                    \n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':best_alpha,'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "\n",
    "                        \n",
    "                        \n",
    "                # test for ridge model\n",
    "                if model_type=='elastic_net':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    best_l1_ratio = 0\n",
    "                    for alpha in self.alphas:\n",
    "                        for l1_ratio in self.l1_ratio:\n",
    "                            model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "                            model.fit(X_train_fold,y_train_fold)\n",
    "                            y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                            non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                            y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                            cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                             print(\"model: {}, alpha: {}, l1_ratio: {},cv_rmse: {}\".format(model_type,alpha,l1_ratio,cv_rmse))\n",
    "                            if cv_rmse<lowest_cv_rmse:\n",
    "                                best_alpha = alpha\n",
    "                                best_l1_ratio = l1_ratio\n",
    "                                lowest_cv_rmse = cv_rmse\n",
    "\n",
    "                    # get the test_rmse for the model\n",
    "                    model = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "\n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':(best_alpha,best_l1_ratio),'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "        \n",
    "    \n",
    "        self.model = best_model\n",
    "        self.model_name = best_model_name\n",
    "        self.res_list = res_list\n",
    "        return self\n",
    "\n",
    "\n",
    "    \n",
    "    def predict(self, path_to_test_csv, *args, **kwargs):\n",
    "        # todo: read test csv\n",
    "        # todo: do any operation you would like on it\n",
    "        self.test = pd.read_csv(path_to_test_csv, index_col='time', parse_dates=['time'])\n",
    "        self.test.index = pd.to_datetime(self.test.index, format='%d-%m-%Y %H:%M')\n",
    "        self.test.sort_index(inplace=True)\n",
    "        self.test = self.test.fillna(method='ffill')\n",
    "    \n",
    "        # todo: prepare features for the model predict\n",
    "        self.y_test = self.get_target(self.test)\n",
    "        self.X_test = self.prepare_features(self.test)\n",
    "        \n",
    "\n",
    "        # todo: calculate your model prediction (call it ypred) using X and any other information you want to use\n",
    "        ypred = pd.Series(np.nan, index=self.X_test.index)\n",
    "        non_nan_rows = ~self.X_test.isnull().any(axis=1)\n",
    "        ypred[non_nan_rows] = self.model.predict(self.X_test[non_nan_rows])\n",
    "\n",
    "        # this follows the scikit-learn pattern by returning ypred\n",
    "        return ypred\n",
    "\n",
    "def get_rmse(ypred,ytest):\n",
    "    combined = pd.concat([ypred, ytest], axis=1)\n",
    "    combined_clean = combined.dropna()\n",
    "    \n",
    "    rmse_ = rmse(combined_clean[0],combined_clean['return'])\n",
    "    return rmse_\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "train_csv_path = '../data/train.csv'\n",
    "test_csv_path = '../data/test.csv'\n",
    "\n",
    "fit_args = ['ols','lasso','ridge','elastic_net']  # todo: populate this as you see fit\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "for l in [0,1,3,5,7,10,14,20,21,22]:\n",
    "    fit_kwargs = {'alphas':np.linspace(0,1,11),'lag':l,'l1_ratio':np.linspace(0,1,11)} # todo: populate this as you see fit\n",
    "    clf = Model()\n",
    "    clf.fit(train_csv_path, *fit_args, **fit_kwargs)\n",
    "    result_df = pd.concat([result_df,pd.DataFrame(clf.res_list)])\n",
    "    print(clf.res_list)\n",
    "\n",
    "result_df.to_csv('result_sel_fe_no_out.csv')\n",
    "\n",
    "predict_args = []  # todo: populate this as you see fit\n",
    "predict_kwargs = {}  # todo: populate this as you see fit\n",
    "ypred = clf.predict(test_csv_path, *predict_args, **predict_kwargs)\n",
    "get_rmse(ypred, clf.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c689772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3646998",
   "metadata": {},
   "source": [
    "# Trial 6: Selected Variables + Feature Engineering + Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e312169",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 0, 'alpha': None, 'test_rmse': 0.017752489288086835}, {'model': 'lasso', 'lag': 0, 'alpha': 0.0, 'test_rmse': 0.01775248928808683}, {'model': 'ridge', 'lag': 0, 'alpha': 0.0, 'test_rmse': 0.017752489288086874}, {'model': 'elastic_net', 'lag': 0, 'alpha': (0.1, 0.0), 'test_rmse': 0.017821821219639735}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 1, 'alpha': None, 'test_rmse': 0.01777407863146158}, {'model': 'lasso', 'lag': 1, 'alpha': 0.0, 'test_rmse': 0.017774078631461618}, {'model': 'ridge', 'lag': 1, 'alpha': 0.0, 'test_rmse': 0.01777407863146168}, {'model': 'elastic_net', 'lag': 1, 'alpha': (0.1, 0.0), 'test_rmse': 0.017821832636603068}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 3, 'alpha': None, 'test_rmse': 0.017773045041599714}, {'model': 'lasso', 'lag': 3, 'alpha': 0.0, 'test_rmse': 0.01777304504159968}, {'model': 'ridge', 'lag': 3, 'alpha': 0.0, 'test_rmse': 0.01777304504159968}, {'model': 'elastic_net', 'lag': 3, 'alpha': (0.1, 0.0), 'test_rmse': 0.017831199020622433}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 5, 'alpha': None, 'test_rmse': 0.017722189631511454}, {'model': 'lasso', 'lag': 5, 'alpha': 0.0, 'test_rmse': 0.017722189631511374}, {'model': 'ridge', 'lag': 5, 'alpha': 0.0, 'test_rmse': 0.017722189631511363}, {'model': 'elastic_net', 'lag': 5, 'alpha': (0.1, 0.0), 'test_rmse': 0.01784506239117754}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 7, 'alpha': None, 'test_rmse': 0.017723957833961263}, {'model': 'lasso', 'lag': 7, 'alpha': 0.0, 'test_rmse': 0.01772395783396124}, {'model': 'ridge', 'lag': 7, 'alpha': 0.0, 'test_rmse': 0.017723957833961253}, {'model': 'elastic_net', 'lag': 7, 'alpha': (0.1, 0.0), 'test_rmse': 0.01785728121059609}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 10, 'alpha': None, 'test_rmse': 0.0178137897277798}, {'model': 'lasso', 'lag': 10, 'alpha': 0.0, 'test_rmse': 0.017813789727779684}, {'model': 'ridge', 'lag': 10, 'alpha': 0.0, 'test_rmse': 0.017813789727779656}, {'model': 'elastic_net', 'lag': 10, 'alpha': (0.1, 0.0), 'test_rmse': 0.017880208962474036}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 14, 'alpha': None, 'test_rmse': 0.017798463852083463}, {'model': 'lasso', 'lag': 14, 'alpha': 0.1, 'test_rmse': 0.017872727806492694}, {'model': 'ridge', 'lag': 14, 'alpha': 1.0, 'test_rmse': 0.017699522665602405}, {'model': 'elastic_net', 'lag': 14, 'alpha': (0.1, 0.0), 'test_rmse': 0.01786046186845285}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 20, 'alpha': None, 'test_rmse': 0.01773455715544337}, {'model': 'lasso', 'lag': 20, 'alpha': 0.1, 'test_rmse': 0.017899092206831904}, {'model': 'ridge', 'lag': 20, 'alpha': 0.0, 'test_rmse': 0.017734557155443503}, {'model': 'elastic_net', 'lag': 20, 'alpha': (0.1, 0.0), 'test_rmse': 0.017890242080126247}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 21, 'alpha': None, 'test_rmse': 0.01774143108352803}, {'model': 'lasso', 'lag': 21, 'alpha': 0.1, 'test_rmse': 0.01789922450465425}, {'model': 'ridge', 'lag': 21, 'alpha': 1.0, 'test_rmse': 0.017642669720668414}, {'model': 'elastic_net', 'lag': 21, 'alpha': (0.1, 0.0), 'test_rmse': 0.01789267727816022}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 22, 'alpha': None, 'test_rmse': 0.017792176593723532}, {'model': 'lasso', 'lag': 22, 'alpha': 0.1, 'test_rmse': 0.01789691999641647}, {'model': 'ridge', 'lag': 22, 'alpha': 1.0, 'test_rmse': 0.01768559810376045}, {'model': 'elastic_net', 'lag': 22, 'alpha': (0.1, 0.0), 'test_rmse': 0.01789485545968275}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01584509949828191"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model:\n",
    "    \n",
    "    def get_target(self,df):\n",
    "        df['return'] = (df['f24'].shift(-78) - df['f24']) / df['f24']\n",
    "        df['return'] = df['return'].replace([np.inf,-np.inf],0)\n",
    "        return df[['return']]\n",
    "    \n",
    "    \n",
    "    def prepare_features(self, df):\n",
    "        \"\"\"\n",
    "        :param df: this is the data you want to use to prepare the features for your model\n",
    "        :return: X, a matrix of features (can be a numpy array or a pandas dataframe, your choice!)\n",
    "        \"\"\"\n",
    "        # todo: implement this function - you can use some of the features given to you or you can build a batch of\n",
    "        #  your own based on the data that you are given.\n",
    "        # *** PLEASE ENSURE THAT DO NOT INTRODUCE A LOOKAHEAD IN THIS MATRIX ***\n",
    "        # *** Bonus points for coding a function that tests against lookahead in X ***\n",
    "        \n",
    "        ## 1. Data Transformation\n",
    "        return_type_columns = ['f0','f1','f2','f3','f11','f12']\n",
    "        price_type_columns = ['f4', 'f5', 'f6', 'f7', 'f8', 'f9',\n",
    "           'f10', 'f13', 'f16', 'f17', 'f18', 'f19',\n",
    "           'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29',\n",
    "           'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39',\n",
    "           'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49',\n",
    "           'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59',\n",
    "           'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69',\n",
    "           'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76']\n",
    "        integer_type_columns = ['f14','f15','f77','f78']\n",
    "\n",
    "        for col in price_type_columns:\n",
    "            df[col] = (df[col] - df[col].shift(78))/df[col].shift(78)\n",
    "    \n",
    "        for col in integer_type_columns:\n",
    "            df[col] = (df[col] - df[col].shift(78))/df[col].shift(78)\n",
    "        \n",
    "        X = df\n",
    "        \n",
    "        # handle case of infinity    \n",
    "        X = X.replace([np.inf],1)\n",
    "        X = X.replace([-np.inf],-1)\n",
    "        \n",
    "        \n",
    "        ## 2. Drop highly correlated variables\n",
    "        X.drop(columns=['f5','f6','f7','f9','f8'],inplace=True)\n",
    "        X.drop(columns=['f25','f26','f28','f29','f31','f32','f34','f35'],inplace=True)\n",
    "        X.drop(columns=['f37','f38','f39','f42','f44','f45','f47','f48'],inplace=True)\n",
    "        X.drop(columns=['f51','f52','f54','f55','f57','f58','f60','f61'],inplace=True)\n",
    "        X.drop(columns=['f65','f64','f67','f63','f71','f70','f74','f73'],inplace=True)\n",
    "        \n",
    "        \n",
    "        ## 3. Outlier Treatment\n",
    "        window_size = 20*79  # 1 month (working days only) \n",
    "        threshold = 2\n",
    "        rolling_mean = X.rolling(window=window_size, min_periods=1).mean()\n",
    "        rolling_std = X.rolling(window=window_size, min_periods=1).std()\n",
    "        lower_bound = rolling_mean - threshold * rolling_std\n",
    "        upper_bound = rolling_mean + threshold * rolling_std\n",
    "        req_cols = list(X.columns)\n",
    "        req_cols.remove('return')\n",
    "        print(\"req_cols without 'return' \", req_cols)\n",
    "        for column in req_cols:   \n",
    "            X[column] = X[column].clip(lower=lower_bound[column], upper=upper_bound[column], axis=0)\n",
    "\n",
    "        # include lag column\n",
    "        column_name = 'return'\n",
    "        for i in range(1, self.lag + 1):\n",
    "            lagged_column_name = f'{column_name}_lag_{i}'\n",
    "            X[lagged_column_name] = X[column_name].shift(i*78)\n",
    "\n",
    "        # delete return columns\n",
    "        del X['return']\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    \n",
    "    def read_data(self,path_to_data):\n",
    "        data = pd.read_csv(path_to_data, index_col='time', parse_dates=['time'])\n",
    "        data.index = pd.to_datetime(data.index, format='%d-%m-%Y %H:%M')\n",
    "        data.sort_index(inplace=True)\n",
    "        data = data.fillna(method='ffill')\n",
    "        return data\n",
    "        \n",
    "    \n",
    "    def fit(self, path_to_train_csv, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        ### AG:  TASKS\n",
    "        ## Model Selection: \n",
    "            Linear: Base Model\n",
    "            Ridge : Handles Multicollinearity\n",
    "            RandomForest (large number of uncorrelated features, fail if the potential y values lie outside)\n",
    "            Time Series\n",
    "        ## Train-Test Split to get the optimal model\n",
    "        ## Train complete model\n",
    "        ## Store the optimal model\n",
    "        \"\"\"\n",
    "        \n",
    "        # get the values from kwargs\n",
    "        self.alphas = kwargs['alphas']\n",
    "        self.lag = kwargs['lag']\n",
    "        self.l1_ratio = kwargs['l1_ratio']\n",
    "        \n",
    "        \n",
    "        # todo: read train csv\n",
    "        # todo: do any operation you would like on it\n",
    "        self.train = self.read_data(path_to_train_csv)\n",
    "        \n",
    "        # todo: prepare features for the model fit\n",
    "        self.y = self.get_target(self.train)\n",
    "        self.X = self.prepare_features(self.train)        \n",
    "        \n",
    "        ## AG: Drop missing values\n",
    "        combined = pd.concat([self.X, self.y], axis=1)\n",
    "        combined_clean = combined.dropna()\n",
    "        self.X_clean = combined_clean.drop(columns='return')\n",
    "        self.y_clean = combined_clean['return']\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Sequential split into train, cv, and test sets\n",
    "        total_length = len(self.X_clean)\n",
    "        train_size = int(total_length * 0.8)  # 60% of data for training\n",
    "#         test_size = int(total_length * 0.2)     # 20% of data for cross-validation\n",
    "\n",
    "        X_train,y_train = self.X_clean[:train_size], self.y_clean[:train_size]\n",
    "        X_test,y_test = self.X_clean[train_size:], self.y_clean[train_size:]\n",
    "\n",
    "        \n",
    "        \n",
    "        # Range of hyperparameters to test for Lasso, Ridge, and Elastic Net\n",
    "        best_alpha = None\n",
    "        lowest_cv_rmse = float('inf')\n",
    "        best_model = None\n",
    "        lowest_rmse = float('inf')\n",
    "        best_model_name = None\n",
    "        \n",
    "        res_list = []\n",
    "        \n",
    "        for model_type in args:\n",
    "            if model_type == 'ols':\n",
    "                model = LinearRegression()\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "#                 print(y_pred)\n",
    "#                 print(y_test)\n",
    "                test_rmse = get_rmse(y_test,y_pred)\n",
    "                res_list.append({'model':model_type,'lag':self.lag,'alpha':None,'test_rmse':test_rmse})\n",
    "                \n",
    "                if test_rmse<lowest_rmse:\n",
    "                    lowest_rmse = test_rmse\n",
    "                    best_model = model\n",
    "                    best_model_name = model_type\n",
    "                    \n",
    "            else:\n",
    "                total_length = len(X_train)\n",
    "                train_size = int(total_length * 0.8)\n",
    "                X_train_fold,y_train_fold = X_train[:train_size], y_train[:train_size]\n",
    "                X_cv_fold,y_cv_fold = X_train[train_size:], y_train[train_size:]\n",
    "\n",
    "                # test for lasso model\n",
    "                if model_type=='lasso':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    for alpha in self.alphas:\n",
    "                        model = Lasso(alpha=alpha)\n",
    "                        model.fit(X_train_fold,y_train_fold)\n",
    "                        y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                        non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                        y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                        cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                         print(\"model: {}, alpha: {}, cv_rmse: {}\".format(model_type,alpha,cv_rmse))\n",
    "                        if cv_rmse<lowest_cv_rmse:\n",
    "                            best_alpha = alpha\n",
    "                            lowest_cv_rmse = cv_rmse\n",
    "                    \n",
    "                    # get the test_rmse for the model\n",
    "                    model = Lasso(alpha=best_alpha)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "                    \n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':best_alpha,'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "\n",
    "            \n",
    "                # test for ridge model\n",
    "                if model_type=='ridge':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    for alpha in self.alphas:\n",
    "                        model = Ridge(alpha=alpha)\n",
    "                        model.fit(X_train_fold,y_train_fold)\n",
    "                        y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                        non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                        y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                        cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                         print(\"model: {}, alpha: {}, cv_rmse: {}\".format(model_type,alpha,cv_rmse))\n",
    "                        if cv_rmse<lowest_cv_rmse:\n",
    "                            best_alpha = alpha\n",
    "                            lowest_cv_rmse = cv_rmse\n",
    "                    \n",
    "                    # get the test_rmse for the model\n",
    "                    model = Ridge(alpha=best_alpha)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "                    \n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':best_alpha,'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "\n",
    "                        \n",
    "                        \n",
    "                # test for ridge model\n",
    "                if model_type=='elastic_net':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    best_l1_ratio = 0\n",
    "                    for alpha in self.alphas:\n",
    "                        for l1_ratio in self.l1_ratio:\n",
    "                            model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "                            model.fit(X_train_fold,y_train_fold)\n",
    "                            y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                            non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                            y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                            cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                             print(\"model: {}, alpha: {}, l1_ratio: {},cv_rmse: {}\".format(model_type,alpha,l1_ratio,cv_rmse))\n",
    "                            if cv_rmse<lowest_cv_rmse:\n",
    "                                best_alpha = alpha\n",
    "                                best_l1_ratio = l1_ratio\n",
    "                                lowest_cv_rmse = cv_rmse\n",
    "\n",
    "                    # get the test_rmse for the model\n",
    "                    model = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "\n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':(best_alpha,best_l1_ratio),'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "        \n",
    "    \n",
    "        self.model = best_model\n",
    "        self.model_name = best_model_name\n",
    "        self.res_list = res_list\n",
    "        return self\n",
    "\n",
    "\n",
    "    \n",
    "    def predict(self, path_to_test_csv, *args, **kwargs):\n",
    "        # todo: read test csv\n",
    "        # todo: do any operation you would like on it\n",
    "        self.test = pd.read_csv(path_to_test_csv, index_col='time', parse_dates=['time'])\n",
    "        self.test.index = pd.to_datetime(self.test.index, format='%d-%m-%Y %H:%M')\n",
    "        self.test.sort_index(inplace=True)\n",
    "        self.test = self.test.fillna(method='ffill')\n",
    "    \n",
    "        # todo: prepare features for the model predict\n",
    "        self.y_test = self.get_target(self.test)\n",
    "        self.X_test = self.prepare_features(self.test)\n",
    "        \n",
    "\n",
    "        # todo: calculate your model prediction (call it ypred) using X and any other information you want to use\n",
    "        ypred = pd.Series(np.nan, index=self.X_test.index)\n",
    "        non_nan_rows = ~self.X_test.isnull().any(axis=1)\n",
    "        ypred[non_nan_rows] = self.model.predict(self.X_test[non_nan_rows])\n",
    "\n",
    "        # this follows the scikit-learn pattern by returning ypred\n",
    "        return ypred\n",
    "\n",
    "def get_rmse(ypred,ytest):\n",
    "    combined = pd.concat([ypred, ytest], axis=1)\n",
    "    combined_clean = combined.dropna()\n",
    "    \n",
    "    rmse_ = rmse(combined_clean[0],combined_clean['return'])\n",
    "    return rmse_\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "train_csv_path = '../data/train.csv'\n",
    "test_csv_path = '../data/test.csv'\n",
    "\n",
    "fit_args = ['ols','lasso','ridge','elastic_net']  # todo: populate this as you see fit\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "for l in [0,1,3,5,7,10,14,20,21,22]:\n",
    "    fit_kwargs = {'alphas':np.linspace(0,1,11),'lag':l,'l1_ratio':np.linspace(0,1,11)} # todo: populate this as you see fit\n",
    "    clf = Model()\n",
    "    clf.fit(train_csv_path, *fit_args, **fit_kwargs)\n",
    "    result_df = pd.concat([result_df,pd.DataFrame(clf.res_list)])\n",
    "    print(clf.res_list)\n",
    "\n",
    "result_df.to_csv('result_sel_fe_out.csv')\n",
    "\n",
    "predict_args = []  # todo: populate this as you see fit\n",
    "predict_kwargs = {}  # todo: populate this as you see fit\n",
    "ypred = clf.predict(test_csv_path, *predict_args, **predict_kwargs)\n",
    "get_rmse(ypred, clf.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96a49ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11ce364",
   "metadata": {},
   "source": [
    "# Trial 9: Selected Variables + Feature Engineering (5 min diff) + Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c437107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 0, 'alpha': None, 'test_rmse': 0.017945940772821408}, {'model': 'lasso', 'lag': 0, 'alpha': 0.0, 'test_rmse': 0.017945766178511773}, {'model': 'ridge', 'lag': 0, 'alpha': 0.1, 'test_rmse': 0.01795284375602802}, {'model': 'elastic_net', 'lag': 0, 'alpha': (0.0, 0.0), 'test_rmse': 0.017945766178511773}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 1, 'alpha': None, 'test_rmse': 0.017963601650155116}, {'model': 'lasso', 'lag': 1, 'alpha': 0.0, 'test_rmse': 0.017963443431573065}, {'model': 'ridge', 'lag': 1, 'alpha': 0.1, 'test_rmse': 0.017969466738212144}, {'model': 'elastic_net', 'lag': 1, 'alpha': (0.0, 0.0), 'test_rmse': 0.017963443431573065}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 3, 'alpha': None, 'test_rmse': 0.017959760468200563}, {'model': 'lasso', 'lag': 3, 'alpha': 0.0, 'test_rmse': 0.01795959325648984}, {'model': 'ridge', 'lag': 3, 'alpha': 1.0, 'test_rmse': 0.017974483804953617}, {'model': 'elastic_net', 'lag': 3, 'alpha': (0.1, 0.0), 'test_rmse': 0.017981083164108975}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 5, 'alpha': None, 'test_rmse': 0.017907157383947752}, {'model': 'lasso', 'lag': 5, 'alpha': 0.0, 'test_rmse': 0.017906979027769}, {'model': 'ridge', 'lag': 5, 'alpha': 1.0, 'test_rmse': 0.01792493671349121}, {'model': 'elastic_net', 'lag': 5, 'alpha': (0.1, 0.0), 'test_rmse': 0.0179928306344177}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 7, 'alpha': None, 'test_rmse': 0.017895420281367296}, {'model': 'lasso', 'lag': 7, 'alpha': 0.0, 'test_rmse': 0.0178952358344072}, {'model': 'ridge', 'lag': 7, 'alpha': 1.0, 'test_rmse': 0.017914603555536777}, {'model': 'elastic_net', 'lag': 7, 'alpha': (0.1, 0.0), 'test_rmse': 0.01800642497652645}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 10, 'alpha': None, 'test_rmse': 0.017977280840688878}, {'model': 'lasso', 'lag': 10, 'alpha': 0.0, 'test_rmse': 0.017977096798331125}, {'model': 'ridge', 'lag': 10, 'alpha': 1.0, 'test_rmse': 0.017991720028477178}, {'model': 'elastic_net', 'lag': 10, 'alpha': (0.0, 0.0), 'test_rmse': 0.017977096798331125}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 14, 'alpha': None, 'test_rmse': 0.01795839319593597}, {'model': 'lasso', 'lag': 14, 'alpha': 0.0, 'test_rmse': 0.01795821281247118}, {'model': 'ridge', 'lag': 14, 'alpha': 1.0, 'test_rmse': 0.017971364241821965}, {'model': 'elastic_net', 'lag': 14, 'alpha': (0.1, 0.0), 'test_rmse': 0.01800709637149492}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 20, 'alpha': None, 'test_rmse': 0.017872966756373745}, {'model': 'lasso', 'lag': 20, 'alpha': 0.1, 'test_rmse': 0.018054486180372798}, {'model': 'ridge', 'lag': 20, 'alpha': 1.0, 'test_rmse': 0.01789039651330463}, {'model': 'elastic_net', 'lag': 20, 'alpha': (0.1, 0.0), 'test_rmse': 0.018042100588291143}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 21, 'alpha': None, 'test_rmse': 0.017878933670703465}, {'model': 'lasso', 'lag': 21, 'alpha': 0.1, 'test_rmse': 0.018052867163253668}, {'model': 'ridge', 'lag': 21, 'alpha': 1.0, 'test_rmse': 0.017896443593405635}, {'model': 'elastic_net', 'lag': 21, 'alpha': (0.1, 0.0), 'test_rmse': 0.018042932073364028}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n",
      "[{'model': 'ols', 'lag': 22, 'alpha': None, 'test_rmse': 0.017921433462995674}, {'model': 'lasso', 'lag': 22, 'alpha': 0.1, 'test_rmse': 0.018052792480720718}, {'model': 'ridge', 'lag': 22, 'alpha': 1.0, 'test_rmse': 0.017936862612105513}, {'model': 'elastic_net', 'lag': 22, 'alpha': (0.1, 0.0), 'test_rmse': 0.018047022942244667}]\n",
      "req_cols without 'return'  ['f0', 'f1', 'f2', 'f3', 'f4', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f27', 'f30', 'f33', 'f36', 'f40', 'f41', 'f43', 'f46', 'f49', 'f50', 'f53', 'f56', 'f59', 'f62', 'f66', 'f68', 'f69', 'f72', 'f75', 'f76', 'f77', 'f78']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01597923285422912"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model:\n",
    "    \n",
    "    def get_target(self,df):\n",
    "        df['return'] = (df['f24'].shift(-78) - df['f24']) / df['f24']\n",
    "        df['return'] = df['return'].replace([np.inf,-np.inf],0)\n",
    "        return df[['return']]\n",
    "    \n",
    "    \n",
    "    def prepare_features(self, df):\n",
    "        \"\"\"\n",
    "        :param df: this is the data you want to use to prepare the features for your model\n",
    "        :return: X, a matrix of features (can be a numpy array or a pandas dataframe, your choice!)\n",
    "        \"\"\"\n",
    "        # todo: implement this function - you can use some of the features given to you or you can build a batch of\n",
    "        #  your own based on the data that you are given.\n",
    "        # *** PLEASE ENSURE THAT DO NOT INTRODUCE A LOOKAHEAD IN THIS MATRIX ***\n",
    "        # *** Bonus points for coding a function that tests against lookahead in X ***\n",
    "        \n",
    "        ## 1. Data Transformation\n",
    "        return_type_columns = ['f0','f1','f2','f3','f11','f12']\n",
    "        price_type_columns = ['f4', 'f5', 'f6', 'f7', 'f8', 'f9',\n",
    "           'f10', 'f13', 'f16', 'f17', 'f18', 'f19',\n",
    "           'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29',\n",
    "           'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39',\n",
    "           'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49',\n",
    "           'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59',\n",
    "           'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69',\n",
    "           'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76']\n",
    "        integer_type_columns = ['f14','f15','f77','f78']\n",
    "\n",
    "        for col in price_type_columns:\n",
    "            df[col] = (df[col] - df[col].shift(1))/df[col].shift(1)\n",
    "    \n",
    "        for col in integer_type_columns:\n",
    "            df[col] = (df[col] - df[col].shift(1))/df[col].shift(1)\n",
    "        \n",
    "        X = df\n",
    "        \n",
    "        # handle case of infinity    \n",
    "        X = X.replace([np.inf],1)\n",
    "        X = X.replace([-np.inf],-1)\n",
    "        \n",
    "        \n",
    "        ## 2. Drop highly correlated variables\n",
    "        X.drop(columns=['f5','f6','f7','f9','f8'],inplace=True)\n",
    "        X.drop(columns=['f25','f26','f28','f29','f31','f32','f34','f35'],inplace=True)\n",
    "        X.drop(columns=['f37','f38','f39','f42','f44','f45','f47','f48'],inplace=True)\n",
    "        X.drop(columns=['f51','f52','f54','f55','f57','f58','f60','f61'],inplace=True)\n",
    "        X.drop(columns=['f65','f64','f67','f63','f71','f70','f74','f73'],inplace=True)\n",
    "        \n",
    "        \n",
    "        ## 3. Outlier Treatment\n",
    "        window_size = 20*79  # 1 month (working days only) \n",
    "        threshold = 2\n",
    "        rolling_mean = X.rolling(window=window_size, min_periods=1).mean()\n",
    "        rolling_std = X.rolling(window=window_size, min_periods=1).std()\n",
    "        lower_bound = rolling_mean - threshold * rolling_std\n",
    "        upper_bound = rolling_mean + threshold * rolling_std\n",
    "        req_cols = list(X.columns)\n",
    "        req_cols.remove('return')\n",
    "        print(\"req_cols without 'return' \", req_cols)\n",
    "        for column in req_cols:   \n",
    "            X[column] = X[column].clip(lower=lower_bound[column], upper=upper_bound[column], axis=0)\n",
    "\n",
    "        # include lag column\n",
    "        column_name = 'return'\n",
    "        for i in range(1, self.lag + 1):\n",
    "            lagged_column_name = f'{column_name}_lag_{i}'\n",
    "            X[lagged_column_name] = X[column_name].shift(i*78)\n",
    "\n",
    "        # delete return columns\n",
    "        del X['return']\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    \n",
    "    def read_data(self,path_to_data):\n",
    "        data = pd.read_csv(path_to_data, index_col='time', parse_dates=['time'])\n",
    "        data.index = pd.to_datetime(data.index, format='%d-%m-%Y %H:%M')\n",
    "        data.sort_index(inplace=True)\n",
    "        data = data.fillna(method='ffill')\n",
    "        return data\n",
    "        \n",
    "    \n",
    "    def fit(self, path_to_train_csv, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        ### AG:  TASKS\n",
    "        ## Model Selection: \n",
    "            Linear: Base Model\n",
    "            Ridge : Handles Multicollinearity\n",
    "            RandomForest (large number of uncorrelated features, fail if the potential y values lie outside)\n",
    "            Time Series\n",
    "        ## Train-Test Split to get the optimal model\n",
    "        ## Train complete model\n",
    "        ## Store the optimal model\n",
    "        \"\"\"\n",
    "        \n",
    "        # get the values from kwargs\n",
    "        self.alphas = kwargs['alphas']\n",
    "        self.lag = kwargs['lag']\n",
    "        self.l1_ratio = kwargs['l1_ratio']\n",
    "        \n",
    "        \n",
    "        # todo: read train csv\n",
    "        # todo: do any operation you would like on it\n",
    "        self.train = self.read_data(path_to_train_csv)\n",
    "        \n",
    "        # todo: prepare features for the model fit\n",
    "        self.y = self.get_target(self.train)\n",
    "        self.X = self.prepare_features(self.train)        \n",
    "        \n",
    "        ## AG: Drop missing values\n",
    "        combined = pd.concat([self.X, self.y], axis=1)\n",
    "        combined_clean = combined.dropna()\n",
    "        self.X_clean = combined_clean.drop(columns='return')\n",
    "        self.y_clean = combined_clean['return']\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Sequential split into train, cv, and test sets\n",
    "        total_length = len(self.X_clean)\n",
    "        train_size = int(total_length * 0.8)  # 60% of data for training\n",
    "#         test_size = int(total_length * 0.2)     # 20% of data for cross-validation\n",
    "\n",
    "        X_train,y_train = self.X_clean[:train_size], self.y_clean[:train_size]\n",
    "        X_test,y_test = self.X_clean[train_size:], self.y_clean[train_size:]\n",
    "\n",
    "        \n",
    "        \n",
    "        # Range of hyperparameters to test for Lasso, Ridge, and Elastic Net\n",
    "        best_alpha = None\n",
    "        lowest_cv_rmse = float('inf')\n",
    "        best_model = None\n",
    "        lowest_rmse = float('inf')\n",
    "        best_model_name = None\n",
    "        \n",
    "        res_list = []\n",
    "        \n",
    "        for model_type in args:\n",
    "            if model_type == 'ols':\n",
    "                model = LinearRegression()\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "#                 print(y_pred)\n",
    "#                 print(y_test)\n",
    "                test_rmse = get_rmse(y_test,y_pred)\n",
    "                res_list.append({'model':model_type,'lag':self.lag,'alpha':None,'test_rmse':test_rmse})\n",
    "                \n",
    "                if test_rmse<lowest_rmse:\n",
    "                    lowest_rmse = test_rmse\n",
    "                    best_model = model\n",
    "                    best_model_name = model_type\n",
    "                    \n",
    "            else:\n",
    "                total_length = len(X_train)\n",
    "                train_size = int(total_length * 0.8)\n",
    "                X_train_fold,y_train_fold = X_train[:train_size], y_train[:train_size]\n",
    "                X_cv_fold,y_cv_fold = X_train[train_size:], y_train[train_size:]\n",
    "\n",
    "                # test for lasso model\n",
    "                if model_type=='lasso':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    for alpha in self.alphas:\n",
    "                        model = Lasso(alpha=alpha)\n",
    "                        model.fit(X_train_fold,y_train_fold)\n",
    "                        y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                        non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                        y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                        cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                         print(\"model: {}, alpha: {}, cv_rmse: {}\".format(model_type,alpha,cv_rmse))\n",
    "                        if cv_rmse<lowest_cv_rmse:\n",
    "                            best_alpha = alpha\n",
    "                            lowest_cv_rmse = cv_rmse\n",
    "                    \n",
    "                    # get the test_rmse for the model\n",
    "                    model = Lasso(alpha=best_alpha)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "                    \n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':best_alpha,'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "\n",
    "            \n",
    "                # test for ridge model\n",
    "                if model_type=='ridge':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    for alpha in self.alphas:\n",
    "                        model = Ridge(alpha=alpha)\n",
    "                        model.fit(X_train_fold,y_train_fold)\n",
    "                        y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                        non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                        y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                        cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                         print(\"model: {}, alpha: {}, cv_rmse: {}\".format(model_type,alpha,cv_rmse))\n",
    "                        if cv_rmse<lowest_cv_rmse:\n",
    "                            best_alpha = alpha\n",
    "                            lowest_cv_rmse = cv_rmse\n",
    "                    \n",
    "                    # get the test_rmse for the model\n",
    "                    model = Ridge(alpha=best_alpha)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "                    \n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':best_alpha,'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "\n",
    "                        \n",
    "                        \n",
    "                # test for ridge model\n",
    "                if model_type=='elastic_net':\n",
    "                    lowest_cv_rmse = float('inf')\n",
    "                    best_l1_ratio = 0\n",
    "                    for alpha in self.alphas:\n",
    "                        for l1_ratio in self.l1_ratio:\n",
    "                            model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "                            model.fit(X_train_fold,y_train_fold)\n",
    "                            y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                            non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                            y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                            cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "#                             print(\"model: {}, alpha: {}, l1_ratio: {},cv_rmse: {}\".format(model_type,alpha,l1_ratio,cv_rmse))\n",
    "                            if cv_rmse<lowest_cv_rmse:\n",
    "                                best_alpha = alpha\n",
    "                                best_l1_ratio = l1_ratio\n",
    "                                lowest_cv_rmse = cv_rmse\n",
    "\n",
    "                    # get the test_rmse for the model\n",
    "                    model = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "\n",
    "                    res_list.append({'model':model_type,'lag':self.lag,'alpha':(best_alpha,best_l1_ratio),'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        lowest_rmse = test_rmse\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "        \n",
    "    \n",
    "        self.model = best_model\n",
    "        self.model_name = best_model_name\n",
    "        self.res_list = res_list\n",
    "        return self\n",
    "\n",
    "\n",
    "    \n",
    "    def predict(self, path_to_test_csv, *args, **kwargs):\n",
    "        # todo: read test csv\n",
    "        # todo: do any operation you would like on it\n",
    "        self.test = pd.read_csv(path_to_test_csv, index_col='time', parse_dates=['time'])\n",
    "        self.test.index = pd.to_datetime(self.test.index, format='%d-%m-%Y %H:%M')\n",
    "        self.test.sort_index(inplace=True)\n",
    "        self.test = self.test.fillna(method='ffill')\n",
    "    \n",
    "        # todo: prepare features for the model predict\n",
    "        self.y_test = self.get_target(self.test)\n",
    "        self.X_test = self.prepare_features(self.test)\n",
    "        \n",
    "\n",
    "        # todo: calculate your model prediction (call it ypred) using X and any other information you want to use\n",
    "        ypred = pd.Series(np.nan, index=self.X_test.index)\n",
    "        non_nan_rows = ~self.X_test.isnull().any(axis=1)\n",
    "        ypred[non_nan_rows] = self.model.predict(self.X_test[non_nan_rows])\n",
    "\n",
    "        # this follows the scikit-learn pattern by returning ypred\n",
    "        return ypred\n",
    "\n",
    "def get_rmse(ypred,ytest):\n",
    "    combined = pd.concat([ypred, ytest], axis=1)\n",
    "    combined_clean = combined.dropna()\n",
    "    \n",
    "    rmse_ = rmse(combined_clean[0],combined_clean['return'])\n",
    "    return rmse_\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "train_csv_path = '../data/train.csv'\n",
    "test_csv_path = '../data/test.csv'\n",
    "\n",
    "fit_args = ['ols','lasso','ridge']  # todo: populate this as you see fit\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "test_result_df = pd.DataFrame()\n",
    "\n",
    "for l in [0,1,3,5]:\n",
    "    fit_kwargs = {'alphas':np.linspace(0,1,11),'lag':l,'l1_ratio':np.linspace(0,1,11)} # todo: populate this as you see fit\n",
    "    clf = Model()\n",
    "    clf.fit(train_csv_path, *fit_args, **fit_kwargs)\n",
    "    result_df = pd.concat([result_df,pd.DataFrame(clf.res_list)])\n",
    "    print(clf.res_list)\n",
    "\n",
    "    predict_args = []  # todo: populate this as you see fit\n",
    "    predict_kwargs = {}  # todo: populate this as you see fit\n",
    "    ypred = clf.predict(test_csv_path, *predict_args, **predict_kwargs)\n",
    "    get_rmse(ypred, clf.y_test)\n",
    "    \n",
    "    clf.model_name\n",
    "    \n",
    "result_df.to_csv('result_sel_5_min_fe_out.csv')\n",
    "\n",
    "predict_args = []  # todo: populate this as you see fit\n",
    "predict_kwargs = {}  # todo: populate this as you see fit\n",
    "ypred = clf.predict(test_csv_path, *predict_args, **predict_kwargs)\n",
    "get_rmse(ypred, clf.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d137992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7bf96e",
   "metadata": {},
   "source": [
    "# Trial 10: Incorporating Model:\n",
    "\n",
    "- Num of Lags\n",
    "- Lag X Variables\n",
    "- Perform Feature Engineering\n",
    "- Perform Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c1b24539",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \n",
    "    def get_target(self,df):\n",
    "        df['return'] = (df['f24'].shift(-78) - df['f24']) / df['f24']\n",
    "        df['return'] = df['return'].replace([np.inf,-np.inf],0)\n",
    "        return df[['return']]\n",
    "    \n",
    "    \n",
    "    def prepare_features(self, df,lag):\n",
    "        \"\"\"\n",
    "        :param df: this is the data you want to use to prepare the features for your model\n",
    "        :return: X, a matrix of features (can be a numpy array or a pandas dataframe, your choice!)\n",
    "        \"\"\"\n",
    "        # todo: implement this function - you can use some of the features given to you or you can build a batch of\n",
    "        #  your own based on the data that you are given.\n",
    "        # *** PLEASE ENSURE THAT DO NOT INTRODUCE A LOOKAHEAD IN THIS MATRIX ***\n",
    "        # *** Bonus points for coding a function that tests against lookahead in X ***\n",
    "        \n",
    "        ## 1. Data Transformation\n",
    "        return_type_columns = ['f0','f1','f2','f3','f11','f12']\n",
    "        price_type_columns = ['f4', 'f5', 'f6', 'f7', 'f8', 'f9',\n",
    "           'f10', 'f13', 'f16', 'f17', 'f18', 'f19',\n",
    "           'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29',\n",
    "           'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39',\n",
    "           'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49',\n",
    "           'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59',\n",
    "           'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69',\n",
    "           'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76']\n",
    "        integer_type_columns = ['f14','f15','f77','f78']\n",
    "\n",
    "        if self.feature_engineering == True:\n",
    "            for col in price_type_columns:\n",
    "                df[col] = (df[col] - df[col].shift(78))/df[col].shift(78)\n",
    "\n",
    "            for col in integer_type_columns:\n",
    "                df[col] = (df[col] - df[col].shift(78))/df[col].shift(78)\n",
    "        \n",
    "        X = df\n",
    "        \n",
    "        # handle case of infinity    \n",
    "        X = X.replace([np.inf],1)\n",
    "        X = X.replace([-np.inf],-1)\n",
    "        \n",
    "        \n",
    "        ## 2. Drop highly correlated variables\n",
    "        X.drop(columns=['f5','f6','f7','f9','f8'],inplace=True)\n",
    "        X.drop(columns=['f25','f26','f28','f29','f31','f32','f34','f35'],inplace=True)\n",
    "        X.drop(columns=['f37','f38','f39','f42','f44','f45','f47','f48'],inplace=True)\n",
    "        X.drop(columns=['f51','f52','f54','f55','f57','f58','f60','f61'],inplace=True)\n",
    "        X.drop(columns=['f65','f64','f67','f63','f71','f70','f74','f73'],inplace=True)\n",
    "        \n",
    "        \n",
    "        ## 3. Outlier Treatment\n",
    "        if self.outlier_treatment==True:\n",
    "            window_size = 20*79  # 1 month (working days only) \n",
    "            threshold = 2\n",
    "            rolling_mean = X.rolling(window=window_size, min_periods=1).mean()\n",
    "            rolling_std = X.rolling(window=window_size, min_periods=1).std()\n",
    "            lower_bound = rolling_mean - threshold * rolling_std\n",
    "            upper_bound = rolling_mean + threshold * rolling_std\n",
    "            req_cols = list(X.columns)\n",
    "            req_cols.remove('return')\n",
    "    #         print(\"req_cols without 'return' \", req_cols)\n",
    "            for column in req_cols:   \n",
    "                X[column] = X[column].clip(lower=lower_bound[column], upper=upper_bound[column], axis=0)\n",
    "\n",
    "\n",
    "        # include lag columns\n",
    "        if self.X_lag == True:\n",
    "            for column_name in X.columns:\n",
    "                for i in range(1, lag + 1):\n",
    "                    lagged_column_name = f'{column_name}_lag_{i}'\n",
    "                    X[lagged_column_name] = X[column_name].shift(i*78)\n",
    "        else:\n",
    "            column_name = 'return'\n",
    "            for i in range(1, lag + 1):\n",
    "                lagged_column_name = f'{column_name}_lag_{i}'\n",
    "                X[lagged_column_name] = X[column_name].shift(i*78)\n",
    "\n",
    "        # delete return columns\n",
    "        del X['return']\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    \n",
    "    def read_data(self,path_to_data):\n",
    "        data = pd.read_csv(path_to_data, index_col='time', parse_dates=['time'])\n",
    "        data.index = pd.to_datetime(data.index, format='%d-%m-%Y %H:%M')\n",
    "        data.sort_index(inplace=True)\n",
    "        data = data.fillna(method='ffill')\n",
    "        return data\n",
    "        \n",
    "    \n",
    "    def fit(self, path_to_train_csv, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        ### AG:  TASKS\n",
    "        ## Model Selection: \n",
    "            Linear: Base Model\n",
    "            Ridge : Handles Multicollinearity\n",
    "            RandomForest (large number of uncorrelated features, fail if the potential y values lie outside)\n",
    "            Time Series\n",
    "        ## Train-Test Split to get the optimal model\n",
    "        ## Train complete model\n",
    "        ## Store the optimal model\n",
    "        \"\"\"\n",
    "        \n",
    "        # get the values from kwargs\n",
    "        self.alphas = kwargs['alphas']\n",
    "        self.lags = kwargs['lags']\n",
    "        self.l1_ratio = kwargs['l1_ratio']\n",
    "        self.X_lag = kwargs['X_lag']\n",
    "        self.outlier_treatment = kwargs['outlier_treatment']\n",
    "        self.feature_engineering = kwargs['feature_engineering']\n",
    "        \n",
    "        \n",
    "        # Range of hyperparameters to test for Lasso, Ridge, and Elastic Net\n",
    "        best_alpha = None\n",
    "        best_l1_ratio = None\n",
    "        best_model = None\n",
    "        best_model_name = None\n",
    "        best_lag = None\n",
    "        lowest_rmse = float('inf')\n",
    "        res_list = []\n",
    "        \n",
    "\n",
    "        \n",
    "        # iterate across lags\n",
    "        for lag in self.lags:\n",
    "            self.train = self.read_data(path_to_train_csv)\n",
    "            self.y = self.get_target(self.train)\n",
    "            \n",
    "            self.X = self.prepare_features(self.train,lag)        \n",
    "\n",
    "            ## AG: Drop missing values\n",
    "            combined = pd.concat([self.X, self.y], axis=1)\n",
    "            combined_clean = combined.dropna()\n",
    "            self.X_clean = combined_clean.drop(columns='return')\n",
    "            self.y_clean = combined_clean['return']\n",
    "\n",
    "\n",
    "            total_length = len(self.X_clean)\n",
    "            train_size = int(total_length * 0.8) \n",
    "            X_train,y_train = self.X_clean[:train_size], self.y_clean[:train_size]\n",
    "            X_test,y_test = self.X_clean[train_size:], self.y_clean[train_size:]\n",
    "\n",
    "\n",
    "\n",
    "            for model_type in args:\n",
    "                if model_type == 'ols':\n",
    "                    model = LinearRegression()\n",
    "                    model.fit(X_train, y_train)\n",
    "#                     print(\"model.coef_: \",model.coef_)\n",
    "                    y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                    non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                    y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                    test_rmse = get_rmse(y_test,y_pred)\n",
    "                    res_list.append({'model':model_type,'lag':lag,'alpha':None,'l1_ratio':None,'test_rmse':test_rmse})\n",
    "                    if test_rmse<lowest_rmse:\n",
    "                        best_alpha = None\n",
    "                        best_l1_ratio = None\n",
    "                        best_model = model\n",
    "                        best_model_name = model_type\n",
    "                        best_lag = lag\n",
    "                        lowest_rmse=test_rmse\n",
    "                    \n",
    "                else:\n",
    "                    total_length = len(X_train)\n",
    "                    train_size = int(total_length * 0.8)\n",
    "                    X_train_fold,y_train_fold = X_train[:train_size], y_train[:train_size]\n",
    "                    X_cv_fold,y_cv_fold = X_train[train_size:], y_train[train_size:]\n",
    "\n",
    "                    # test for lasso model\n",
    "                    if model_type=='lasso':\n",
    "                        lowest_cv_rmse = float('inf')\n",
    "                        best_model_alpha = None\n",
    "                        for alpha in self.alphas:\n",
    "#                             print(alpha)\n",
    "#                             print(X_train_fold,y_train_fold)\n",
    "                            model = Lasso(alpha=alpha)\n",
    "                            model.fit(X_train_fold,y_train_fold)\n",
    "                            y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                            non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                            y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                            cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "                            if cv_rmse<lowest_cv_rmse:\n",
    "                                best_model_alpha = alpha\n",
    "                                lowest_cv_rmse = cv_rmse\n",
    "\n",
    "                        # get the test_rmse for the model\n",
    "                        model = Lasso(alpha=best_model_alpha)\n",
    "                        model.fit(X_train, y_train)\n",
    "                        y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                        non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                        y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                        test_rmse = get_rmse(y_test,y_pred)\n",
    "    \n",
    "                        res_list.append({'model':model_type,'lag':lag,'alpha':best_model_alpha,'l1_ratio':None,'test_rmse':test_rmse})\n",
    "                        if test_rmse<lowest_rmse:\n",
    "                            best_alpha = best_model_alpha\n",
    "                            best_l1_ratio = None\n",
    "                            best_model = model\n",
    "                            best_model_name = model_type\n",
    "                            best_lag = lag\n",
    "                            lowest_rmse=test_rmse\n",
    "\n",
    "\n",
    "\n",
    "                    # test for ridge model\n",
    "                    if model_type=='ridge':\n",
    "                        lowest_cv_rmse = float('inf')\n",
    "                        best_model_alpha = None\n",
    "                        for alpha in self.alphas:\n",
    "                            model = Ridge(alpha=alpha)\n",
    "                            model.fit(X_train_fold,y_train_fold)\n",
    "                            y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                            non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                            y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                            cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "    #                         print(\"model: {}, alpha: {}, cv_rmse: {}\".format(model_type,alpha,cv_rmse))\n",
    "                            if cv_rmse<lowest_cv_rmse:\n",
    "                                best_model_alpha = alpha\n",
    "                                lowest_cv_rmse = cv_rmse\n",
    "\n",
    "                        # get the test_rmse for the model\n",
    "                        model = Ridge(alpha=best_model_alpha)\n",
    "                        model.fit(X_train, y_train)\n",
    "                        y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                        non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                        y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                        test_rmse = get_rmse(y_test,y_pred)\n",
    "\n",
    "                        res_list.append({'model':model_type,'lag':lag,'alpha':best_model_alpha,'l1_ratio':None,'test_rmse':test_rmse})\n",
    "                        if test_rmse<lowest_rmse:\n",
    "                            best_alpha = best_model_alpha\n",
    "                            best_l1_ratio = None\n",
    "                            best_model = model\n",
    "                            best_model_name = model_type\n",
    "                            best_lag = lag\n",
    "                            lowest_rmse=test_rmse\n",
    "\n",
    "\n",
    "\n",
    "                    # test for ridge model\n",
    "                    if model_type=='elastic_net':\n",
    "                        lowest_cv_rmse = float('inf')\n",
    "                        best_model_l1_ratio = 0\n",
    "                        best_model_alpha = None\n",
    "                        for alpha in self.alphas:\n",
    "                            for l1_ratio in self.l1_ratio:\n",
    "                                model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "                                model.fit(X_train_fold,y_train_fold)\n",
    "                                y_cv_pred = pd.Series(np.nan, index=X_cv_fold.index)\n",
    "                                non_nan_rows = ~X_cv_fold.isnull().any(axis=1)\n",
    "                                y_cv_pred[non_nan_rows] = model.predict(X_cv_fold[non_nan_rows])\n",
    "                                cv_rmse = get_rmse(y_cv_fold,y_cv_pred)\n",
    "    #                             print(\"model: {}, alpha: {}, l1_ratio: {},cv_rmse: {}\".format(model_type,alpha,l1_ratio,cv_rmse))\n",
    "                                if cv_rmse<lowest_cv_rmse:\n",
    "                                    best_model_alpha = alpha\n",
    "                                    best_model_l1_ratio = l1_ratio\n",
    "                                    lowest_cv_rmse = cv_rmse\n",
    "\n",
    "                        # get the test_rmse for the model\n",
    "                        model = ElasticNet(alpha=best_model_alpha, l1_ratio=best_model_l1_ratio)\n",
    "                        model.fit(X_train, y_train)\n",
    "                        y_pred = pd.Series(np.nan, index=X_test.index)\n",
    "                        non_nan_rows = ~X_test.isnull().any(axis=1)\n",
    "                        y_pred[non_nan_rows] = model.predict(X_test[non_nan_rows])\n",
    "                        test_rmse = get_rmse(y_test,y_pred)\n",
    "\n",
    "                        res_list.append({'model':model_type,'lag':lag,'alpha':best_model_alpha,'l1_ratio':best_model_l1_ratio,'test_rmse':test_rmse})\n",
    "                        if test_rmse<lowest_rmse:\n",
    "                            best_alpha = best_model_alpha\n",
    "                            best_l1_ratio = best_model_l1_ratio\n",
    "                            best_model = model\n",
    "                            best_model_name = model_type\n",
    "                            best_lag = lag\n",
    "                            lowest_rmse=test_rmse\n",
    "        \n",
    "    \n",
    "        self.model = best_model\n",
    "        self.model_name = best_model_name\n",
    "        self.res_list = res_list\n",
    "        self.lag = best_lag\n",
    "        self.alpha = best_alpha\n",
    "        self.l1_ratio = best_l1_ratio\n",
    "        self.rmse = lowest_rmse\n",
    "        \n",
    "        return self\n",
    "\n",
    "\n",
    "    \n",
    "    def predict(self, path_to_test_csv, *args, **kwargs):\n",
    "        # todo: read test csv\n",
    "        # todo: do any operation you would like on it\n",
    "        self.test = pd.read_csv(path_to_test_csv, index_col='time', parse_dates=['time'])\n",
    "        self.test.index = pd.to_datetime(self.test.index, format='%d-%m-%Y %H:%M')\n",
    "        self.test.sort_index(inplace=True)\n",
    "        self.test = self.test.fillna(method='ffill')\n",
    "    \n",
    "        # todo: prepare features for the model predict\n",
    "        self.y_test = self.get_target(self.test)\n",
    "#         print(\"self.lag: \",self.lag)\n",
    "        self.X_test = self.prepare_features(self.test,self.lag)\n",
    "        \n",
    "\n",
    "        # todo: calculate your model prediction (call it ypred) using X and any other information you want to use\n",
    "        ypred = pd.Series(np.nan, index=self.X_test.index)\n",
    "        non_nan_rows = ~self.X_test.isnull().any(axis=1)\n",
    "        ypred[non_nan_rows] = self.model.predict(self.X_test[non_nan_rows])\n",
    "\n",
    "        # this follows the scikit-learn pattern by returning ypred\n",
    "        return ypred\n",
    "\n",
    "def get_rmse(ypred,ytest):\n",
    "    combined = pd.concat([ypred, ytest], axis=1)\n",
    "    combined_clean = combined.dropna()\n",
    "    \n",
    "    rmse_ = rmse(combined_clean[0],combined_clean['return'])\n",
    "    return rmse_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7e44e4",
   "metadata": {},
   "source": [
    "### 10.1 Include X Lag + Outlier Treatment + Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "87a7350c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01581098734827609"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'xlag_out_fe'\n",
    "fit_args = ['ols','lasso','ridge']#['ols','lasso','ridge','elastic_net']  # todo: populate this as you see fit\n",
    "fit_kwargs = {'alphas':np.linspace(0,1,11),'lags':[0,1,3,5],'l1_ratio':np.linspace(0,1,11),'X_lag':True, \n",
    "              'outlier_treatment':True, 'feature_engineering':True} \n",
    "\n",
    "\n",
    "# DON\"T CHANGE IT\n",
    "train_csv_path = '../data/train.csv'\n",
    "test_csv_path = '../data/test.csv'\n",
    "\n",
    "#'alphas':np.linspace(0,1,11) # 'l1_ratio':np.linspace(0,1,11) # todo: populate this as you see fit \n",
    "\n",
    "\n",
    "clf = Model()\n",
    "clf.fit(train_csv_path, *fit_args, **fit_kwargs)\n",
    "\n",
    "res_df = pd.DataFrame(clf.res_list)\n",
    "res_df.to_csv(filename)\n",
    "\n",
    "predict_args = []  # todo: populate this as you see fit\n",
    "predict_kwargs = {}  # todo: populate this as you see fit\n",
    "ypred = clf.predict(test_csv_path, *predict_args, **predict_kwargs)\n",
    "\n",
    "# save lowest rmse\n",
    "pd.DataFrame([{'name':filename,'rmse':get_rmse(ypred, clf.y_test)}]).to_csv('res_{}.csv'.format(filename))\n",
    "\n",
    "get_rmse(ypred, clf.y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d140ac74",
   "metadata": {},
   "source": [
    "### 10.2 Include X Lag + No Outlier Treatment + Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "98f864d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01579722527711066"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'xlag_no_out_fe'\n",
    "fit_args = ['ols','lasso','ridge']#['ols','lasso','ridge','elastic_net']  # todo: populate this as you see fit\n",
    "fit_kwargs = {'alphas':np.linspace(0,1,11),'lags':[0,1,3,5],'l1_ratio':np.linspace(0,1,11),'X_lag':True, \n",
    "              'outlier_treatment':False, 'feature_engineering':True} \n",
    "\n",
    "\n",
    "# DON\"T CHANGE IT\n",
    "train_csv_path = '../data/train.csv'\n",
    "test_csv_path = '../data/test.csv'\n",
    "\n",
    "#'alphas':np.linspace(0,1,11) # 'l1_ratio':np.linspace(0,1,11) # todo: populate this as you see fit \n",
    "\n",
    "\n",
    "clf = Model()\n",
    "clf.fit(train_csv_path, *fit_args, **fit_kwargs)\n",
    "\n",
    "res_df = pd.DataFrame(clf.res_list)\n",
    "res_df.to_csv(filename)\n",
    "\n",
    "predict_args = []  # todo: populate this as you see fit\n",
    "predict_kwargs = {}  # todo: populate this as you see fit\n",
    "ypred = clf.predict(test_csv_path, *predict_args, **predict_kwargs)\n",
    "\n",
    "# save lowest rmse\n",
    "pd.DataFrame([{'name':filename,'rmse':get_rmse(ypred, clf.y_test)}]).to_csv('res_{}.csv'.format(filename))\n",
    "\n",
    "get_rmse(ypred, clf.y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f2f088",
   "metadata": {},
   "source": [
    "### 10.3 Include X Lag + Outlier Treatment + No Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdece49",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'xlag_out_no_fe'\n",
    "fit_args = ['ols','lasso','ridge','elastic_net']  # todo: populate this as you see fit\n",
    "fit_kwargs = {'alphas':np.linspace(0,1,11),'lags':[0,1,3,5,7,10,14,15,20,21,22,30],'l1_ratio':np.linspace(0,1,11),\n",
    "              'X_lag':True,'outlier_treatment':True, 'feature_engineering':False} \n",
    "\n",
    "\n",
    "# DON\"T CHANGE IT\n",
    "train_csv_path = '../data/train.csv'\n",
    "test_csv_path = '../data/test.csv'\n",
    "\n",
    "#'alphas':np.linspace(0,1,11) # 'l1_ratio':np.linspace(0,1,11) # todo: populate this as you see fit \n",
    "\n",
    "\n",
    "clf = Model()\n",
    "clf.fit(train_csv_path, *fit_args, **fit_kwargs)\n",
    "\n",
    "res_df = pd.DataFrame(clf.res_list)\n",
    "res_df.to_csv(filename)\n",
    "\n",
    "predict_args = []  # todo: populate this as you see fit\n",
    "predict_kwargs = {}  # todo: populate this as you see fit\n",
    "ypred = clf.predict(test_csv_path, *predict_args, **predict_kwargs)\n",
    "\n",
    "# save lowest rmse\n",
    "pd.DataFrame([{'name':filename,'rmse':get_rmse(ypred, clf.y_test)}]).to_csv('res_{}.csv'.format(filename))\n",
    "\n",
    "get_rmse(ypred, clf.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4a70f8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015549315499417522"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'xlag_out_no_fe'\n",
    "fit_args = ['ols','lasso','ridge']#['ols','lasso','ridge','elastic_net']  # todo: populate this as you see fit\n",
    "fit_kwargs = {'alphas':np.linspace(0,1,11),'lags':[0,1,3,5],'l1_ratio':np.linspace(0,1,11),'X_lag':True, \n",
    "              'outlier_treatment':True, 'feature_engineering':False} \n",
    "\n",
    "\n",
    "# DON\"T CHANGE IT\n",
    "train_csv_path = '../data/train.csv'\n",
    "test_csv_path = '../data/test.csv'\n",
    "\n",
    "#'alphas':np.linspace(0,1,11) # 'l1_ratio':np.linspace(0,1,11) # todo: populate this as you see fit \n",
    "\n",
    "\n",
    "clf = Model()\n",
    "clf.fit(train_csv_path, *fit_args, **fit_kwargs)\n",
    "\n",
    "res_df = pd.DataFrame(clf.res_list)\n",
    "res_df.to_csv(filename)\n",
    "\n",
    "predict_args = []  # todo: populate this as you see fit\n",
    "predict_kwargs = {}  # todo: populate this as you see fit\n",
    "ypred = clf.predict(test_csv_path, *predict_args, **predict_kwargs)\n",
    "\n",
    "# save lowest rmse\n",
    "pd.DataFrame([{'name':filename,'rmse':get_rmse(ypred, clf.y_test)}]).to_csv('res_{}.csv'.format(filename))\n",
    "\n",
    "get_rmse(ypred, clf.y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ee6171",
   "metadata": {},
   "source": [
    "### 10.4 Include X Lag + No Outlier Treatment + No Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "85f6b6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015554571417591461"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'xlag_no_out_no_fe'\n",
    "fit_args = ['ols','lasso','ridge']#['ols','lasso','ridge','elastic_net']  # todo: populate this as you see fit\n",
    "fit_kwargs = {'alphas':np.linspace(0,1,11),'lags':[0,1,3,5],'l1_ratio':np.linspace(0,1,11),'X_lag':True, \n",
    "              'outlier_treatment':False, 'feature_engineering':False} \n",
    "\n",
    "\n",
    "# DON\"T CHANGE IT\n",
    "train_csv_path = '../data/train.csv'\n",
    "test_csv_path = '../data/test.csv'\n",
    "\n",
    "#'alphas':np.linspace(0,1,11) # 'l1_ratio':np.linspace(0,1,11) # todo: populate this as you see fit \n",
    "\n",
    "\n",
    "clf = Model()\n",
    "clf.fit(train_csv_path, *fit_args, **fit_kwargs)\n",
    "\n",
    "res_df = pd.DataFrame(clf.res_list)\n",
    "res_df.to_csv(filename)\n",
    "\n",
    "predict_args = []  # todo: populate this as you see fit\n",
    "predict_kwargs = {}  # todo: populate this as you see fit\n",
    "ypred = clf.predict(test_csv_path, *predict_args, **predict_kwargs)\n",
    "\n",
    "# save lowest rmse\n",
    "pd.DataFrame([{'name':filename,'rmse':get_rmse(ypred, clf.y_test)}]).to_csv('res_{}.csv'.format(filename))\n",
    "\n",
    "get_rmse(ypred, clf.y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d534d7",
   "metadata": {},
   "source": [
    "### 10.5 Exclude X Lag + Outlier Treatment + Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "94de67a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01589682232044508"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'np_xlag_out_fe'\n",
    "fit_args = ['ols','lasso','ridge']#['ols','lasso','ridge','elastic_net']  # todo: populate this as you see fit\n",
    "fit_kwargs = {'alphas':np.linspace(0,1,11),'lags':[0,1,3,5],'l1_ratio':np.linspace(0,1,11),'X_lag':False, \n",
    "              'outlier_treatment':True, 'feature_engineering':True} \n",
    "\n",
    "\n",
    "# DON\"T CHANGE IT\n",
    "train_csv_path = '../data/train.csv'\n",
    "test_csv_path = '../data/test.csv'\n",
    "\n",
    "#'alphas':np.linspace(0,1,11) # 'l1_ratio':np.linspace(0,1,11) # todo: populate this as you see fit \n",
    "\n",
    "\n",
    "clf = Model()\n",
    "clf.fit(train_csv_path, *fit_args, **fit_kwargs)\n",
    "\n",
    "res_df = pd.DataFrame(clf.res_list)\n",
    "res_df.to_csv(filename)\n",
    "\n",
    "predict_args = []  # todo: populate this as you see fit\n",
    "predict_kwargs = {}  # todo: populate this as you see fit\n",
    "ypred = clf.predict(test_csv_path, *predict_args, **predict_kwargs)\n",
    "\n",
    "# save lowest rmse\n",
    "pd.DataFrame([{'name':filename,'rmse':get_rmse(ypred, clf.y_test)}]).to_csv('res_{}.csv'.format(filename))\n",
    "\n",
    "get_rmse(ypred, clf.y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0fc3f0",
   "metadata": {},
   "source": [
    "### 10.6 Exclude X Lag + No Outlier Treatment + Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d09f1801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01584243176906051"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'no_xlag_no_out_fe'\n",
    "fit_args = ['ols','lasso','ridge']#['ols','lasso','ridge','elastic_net']  # todo: populate this as you see fit\n",
    "fit_kwargs = {'alphas':np.linspace(0,1,11),'lags':[0,1,3,5],'l1_ratio':np.linspace(0,1,11),'X_lag':False, \n",
    "              'outlier_treatment':False, 'feature_engineering':True} \n",
    "\n",
    "\n",
    "# DON\"T CHANGE IT\n",
    "train_csv_path = '../data/train.csv'\n",
    "test_csv_path = '../data/test.csv'\n",
    "\n",
    "#'alphas':np.linspace(0,1,11) # 'l1_ratio':np.linspace(0,1,11) # todo: populate this as you see fit \n",
    "\n",
    "\n",
    "clf = Model()\n",
    "clf.fit(train_csv_path, *fit_args, **fit_kwargs)\n",
    "\n",
    "res_df = pd.DataFrame(clf.res_list)\n",
    "res_df.to_csv(filename)\n",
    "\n",
    "predict_args = []  # todo: populate this as you see fit\n",
    "predict_kwargs = {}  # todo: populate this as you see fit\n",
    "ypred = clf.predict(test_csv_path, *predict_args, **predict_kwargs)\n",
    "\n",
    "# save lowest rmse\n",
    "pd.DataFrame([{'name':filename,'rmse':get_rmse(ypred, clf.y_test)}]).to_csv('res_{}.csv'.format(filename))\n",
    "\n",
    "get_rmse(ypred, clf.y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b702dafa",
   "metadata": {},
   "source": [
    "### 10.7 Exclude X Lag + Outlier Treatment + No Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6958347b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015575285611033572"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'no_xlag_out_no_fe'\n",
    "fit_args = ['ols','lasso','ridge']#['ols','lasso','ridge','elastic_net']  # todo: populate this as you see fit\n",
    "fit_kwargs = {'alphas':np.linspace(0,1,11),'lags':[0,1,3,5],'l1_ratio':np.linspace(0,1,11),'X_lag':False, \n",
    "              'outlier_treatment':True, 'feature_engineering':False} \n",
    "\n",
    "\n",
    "# DON\"T CHANGE IT\n",
    "train_csv_path = '../data/train.csv'\n",
    "test_csv_path = '../data/test.csv'\n",
    "\n",
    "#'alphas':np.linspace(0,1,11) # 'l1_ratio':np.linspace(0,1,11) # todo: populate this as you see fit \n",
    "\n",
    "\n",
    "clf = Model()\n",
    "clf.fit(train_csv_path, *fit_args, **fit_kwargs)\n",
    "\n",
    "res_df = pd.DataFrame(clf.res_list)\n",
    "res_df.to_csv(filename)\n",
    "\n",
    "predict_args = []  # todo: populate this as you see fit\n",
    "predict_kwargs = {}  # todo: populate this as you see fit\n",
    "ypred = clf.predict(test_csv_path, *predict_args, **predict_kwargs)\n",
    "\n",
    "# save lowest rmse\n",
    "pd.DataFrame([{'name':filename,'rmse':get_rmse(ypred, clf.y_test)}]).to_csv('res_{}.csv'.format(filename))\n",
    "\n",
    "get_rmse(ypred, clf.y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5dd457",
   "metadata": {},
   "source": [
    "### 10.8 Exclude X Lag + No Outlier Treatment + No Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a738c23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015581663907108172"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'no_xlag_no_out_no_fe'\n",
    "fit_args = ['ols','lasso','ridge']#['ols','lasso','ridge','elastic_net']  # todo: populate this as you see fit\n",
    "fit_kwargs = {'alphas':np.linspace(0,1,11),'lags':[0,1,3,5],'l1_ratio':np.linspace(0,1,11),'X_lag':False, \n",
    "              'outlier_treatment':False, 'feature_engineering':False} \n",
    "\n",
    "\n",
    "# DON\"T CHANGE IT\n",
    "train_csv_path = '../data/train.csv'\n",
    "test_csv_path = '../data/test.csv'\n",
    "\n",
    "#'alphas':np.linspace(0,1,11) # 'l1_ratio':np.linspace(0,1,11) # todo: populate this as you see fit \n",
    "\n",
    "\n",
    "clf = Model()\n",
    "clf.fit(train_csv_path, *fit_args, **fit_kwargs)\n",
    "\n",
    "res_df = pd.DataFrame(clf.res_list)\n",
    "res_df.to_csv(filename)\n",
    "\n",
    "predict_args = []  # todo: populate this as you see fit\n",
    "predict_kwargs = {}  # todo: populate this as you see fit\n",
    "ypred = clf.predict(test_csv_path, *predict_args, **predict_kwargs)\n",
    "\n",
    "# save lowest rmse\n",
    "pd.DataFrame([{'name':filename,'rmse':get_rmse(ypred, clf.y_test)}]).to_csv('res_{}.csv'.format(filename))\n",
    "\n",
    "get_rmse(ypred, clf.y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
